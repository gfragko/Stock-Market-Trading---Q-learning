{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project 2: Stock Portfolio Optimization - Assignment 3**\n",
    " Athanasakis Evangelos 2019030118  \n",
    " Fragkogiannis Yiorgos 2019030039"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # **Project 2: Stock Portfolio Optimization - Assignment 3**\n",
    "# Athanasakis Evangelos 2019030118 // Fragkogiannis Yiorgos 2019030039\n",
    "\n",
    "\n",
    "# Importing libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tkinter as tk #loads standard python GUI libraries\n",
    "import random\n",
    "from tkinter import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------__________________Environments___________________-------------------------------------------------------------------------\n",
    "# Generating environments\n",
    "\n",
    "\n",
    "# Create the three different environments\n",
    "# We are modeling this environment using 8 states in the format: {stock_currently_holding,state_of_stock_1,state_of_stock_2}\n",
    "\n",
    "action_keep = 0     # keep the same stock\n",
    "action_switch = 1   # switch to the other stock\n",
    "\n",
    "# This environment is used for the question 1 where we need to demonstrate that the optimal\n",
    "# policy is always to stay with the stock we already have invested\n",
    "fee = -0.9\n",
    "# r1H = 2*r2L\n",
    "# in this case r1.h=0.1 // r2.H= 0.05 // r1.L = -0.02 // r2.L = 0.01\n",
    "# we have used a large transaction fee so that the best policy will always be to keep using the same stock\n",
    "P1 = {\n",
    "\n",
    "    # State {1,L,L}\n",
    "    0:{\n",
    "        action_keep: [\n",
    "             (9/20, 0, -0.02),    # probability: 9/20, next_State: {1,L,L}, Reward: -0.02\n",
    "             (1/20, 1, -0.02),    # {1,L,H}\n",
    "             (9/20, 2, +0.1),     # {1,H,L}\n",
    "             (1/20, 3, +0.1)      # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (9/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (1/20, 5, +0.05 + fee),    # {2,L,H}\n",
    "            (9/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (1/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {1,L,H}\n",
    "    1:{\n",
    "        action_keep: [\n",
    "             (1/20, 0, -0.02),  # {1,L,L}\n",
    "             (9/20, 1, -0.02),  # {1,L,H}\n",
    "             (1/20, 2, +0.1 ),  # {1,H,L}\n",
    "             (9/20, 3, +0.1 )   # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (1/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (9/20, 5, +0.05 + fee),    # {2,L,H}\n",
    "            (1/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (9/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {1,H,L}\n",
    "    2:{\n",
    "        action_keep: [\n",
    "             (9/20, 0, -0.02),  # {1,L,L}\n",
    "             (1/20, 1, -0.02),  # {1,L,H}\n",
    "             (9/20, 2, +0.1 ),  # {1,H,L}\n",
    "             (1/20, 3, +0.1 )   # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (9/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (1/20, 5, +0.05 + fee),    # {2,L,H}\n",
    "            (9/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (1/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {1,H,H}\n",
    "    3:{\n",
    "        action_keep: [\n",
    "             (1/20, 0, -0.02),  # {1,L,L}\n",
    "             (9/20, 1, -0.02),  # {1,L,H}\n",
    "             (1/20, 2, +0.1 ),  # {1,H,L}\n",
    "             (9/20, 3, +0.1 )   # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch: [\n",
    "            (1/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (9/20, 5, +0.05 + fee),    # {2,L,H}\n",
    "            (1/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (9/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,L,L}\n",
    "    4:{\n",
    "        action_keep: [\n",
    "             (9/20, 4,  +0.01),    # {2,L,L}\n",
    "             (1/20, 5,  +0.05),    # {2,L,H}\n",
    "             (9/20, 6,  +0.01),    # {2,H,L}\n",
    "             (1/20, 7,  +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "             (9/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "             (1/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "             (9/20, 2, +0.1  + fee),  # {1,H,L}\n",
    "             (1/20, 3, +0.1  + fee)   # {1,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,L,H}\n",
    "    5:{\n",
    "        action_keep: [\n",
    "             (1/20, 4, +0.01),    # {2,L,L}\n",
    "             (9/20, 5, +0.05),    # {2,L,H}\n",
    "             (1/20, 6, +0.01),    # {2,H,L}\n",
    "             (9/20, 7, +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (1/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "            (9/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "            (1/20, 2, +0.1  + fee),  # {1,H,L}\n",
    "            (9/20, 3, +0.1  + fee)   # {1,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,H,L}\n",
    "    6:{\n",
    "        action_keep: [\n",
    "             (9/20, 4, +0.01),    # {2,L,L}\n",
    "             (1/20, 5, +0.05),    # {2,L,H}\n",
    "             (9/20, 6, +0.01),    # {2,H,L}\n",
    "             (1/20, 7, +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "             (9/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "             (1/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "             (9/20, 2, +0.1  + fee),  # {1,H,L}\n",
    "             (1/20, 3, +0.1  + fee)   # {1,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,H,H}\n",
    "    7:{\n",
    "        action_keep: [\n",
    "             (1/20, 4, +0.01),    # {2,L,L}\n",
    "             (9/20, 5, +0.05),    # {2,L,H}\n",
    "             (1/20, 6, +0.01),    # {2,H,L}\n",
    "             (9/20, 7, +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "             (1/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "             (9/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "             (1/20, 2, +0.1  + fee),  # {1,H,L}\n",
    "             (9/20, 3, +0.1  + fee)   # {1,H,H}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# This environment implements the stocks environment from the midterm\n",
    "# It is used for the question 2 where we need to demonstrate that the optimal policy\n",
    "# for some of the states is to switch and in some others to stay\n",
    "fee = -0.01\n",
    "P2 = {\n",
    "\n",
    "    # State {1,L,L}\n",
    "    0:{\n",
    "        action_keep: [\n",
    "             (9/20, 0, -0.02),    # probability: 9/20, next_State: {1,L,L}, Reward: -0.02\n",
    "             (1/20, 1, -0.02),    # {1,L,H}\n",
    "             (9/20, 2, +0.1),     # {1,H,L}\n",
    "             (1/20, 3, +0.1)      # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (9/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (1/20, 5, +0.05 + fee),    # {2,L,H}\n",
    "            (9/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (1/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {1,L,H}\n",
    "    1:{\n",
    "        action_keep: [\n",
    "             (1/20, 0, -0.02),  # {1,L,L}\n",
    "             (9/20, 1, -0.02),  # {1,L,H}\n",
    "             (1/20, 2, +0.1 ),  # {1,H,L}\n",
    "             (9/20, 3, +0.1 )   # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (1/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (9/20, 5, +0.05 + fee),    # {2,L,H}\n",
    "            (1/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (9/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {1,H,L}\n",
    "    2:{\n",
    "        action_keep: [\n",
    "             (9/20, 0, -0.02),  # {1,L,L}\n",
    "             (1/20, 1, -0.02),  # {1,L,H}\n",
    "             (9/20, 2, +0.1 ),  # {1,H,L}\n",
    "             (1/20, 3, +0.1 )   # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (9/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (1/20, 5, +0.05 + fee),    # {2,L,H}\n",
    "            (9/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (1/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {1,H,H}\n",
    "    3:{\n",
    "        action_keep: [\n",
    "             (1/20, 0, -0.02),  # {1,L,L}\n",
    "             (9/20, 1, -0.02),  # {1,L,H}\n",
    "             (1/20, 2, +0.1 ),  # {1,H,L}\n",
    "             (9/20, 3, +0.1 )   # {1,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch: [\n",
    "            (1/20, 4, +0.01 + fee),    # {2,L,L}\n",
    "            (9/20, 5, +0.05  + fee),    # {2,L,H}\n",
    "            (1/20, 6, +0.01 + fee),    # {2,H,L}\n",
    "            (9/20, 7, +0.05 + fee)     # {2,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,L,L}\n",
    "    4:{\n",
    "        action_keep: [\n",
    "             (9/20, 4,  +0.01),    # {2,L,L}\n",
    "             (1/20, 5,  +0.05),    # {2,L,H}\n",
    "             (9/20, 6,  +0.01),    # {2,H,L}\n",
    "             (1/20, 7,  +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "             (9/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "             (1/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "             (9/20, 2, +0.1 + fee),  # {1,H,L}\n",
    "             (1/20, 3, +0.1 + fee)   # {1,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,L,H}\n",
    "    5:{\n",
    "        action_keep: [\n",
    "             (1/20, 4, +0.01),    # {2,L,L}\n",
    "             (9/20, 5, +0.05),    # {2,L,H}\n",
    "             (1/20, 6, +0.01),    # {2,H,L}\n",
    "             (9/20, 7, +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "            (1/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "            (9/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "            (1/20, 2, +0.1 + fee),  # {1,H,L}\n",
    "            (9/20, 3, +0.1 + fee)   # {1,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,H,L}\n",
    "    6:{\n",
    "        action_keep: [\n",
    "             (9/20, 4, +0.01),    # {2,L,L}\n",
    "             (1/20, 5, +0.05),    # {2,L,H}\n",
    "             (9/20, 6, +0.01),    # {2,H,L}\n",
    "             (1/20, 7, +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "             (9/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "             (1/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "             (9/20, 2, +0.1 + fee),  # {1,H,L}\n",
    "             (1/20, 3, +0.1 + fee)   # {1,H,H}\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # State {2,H,H}\n",
    "    7:{\n",
    "        action_keep: [\n",
    "             (1/20, 4, +0.01),    # {2,L,L}\n",
    "             (9/20, 5, +0.05),    # {2,L,H}\n",
    "             (1/20, 6, +0.01),    # {2,H,L}\n",
    "             (9/20, 7, +0.05)     # {2,H,H}\n",
    "        ],\n",
    "\n",
    "        action_switch:[\n",
    "             (1/20, 0, -0.02 + fee),  # {1,L,L}\n",
    "             (9/20, 1, -0.02 + fee),  # {1,L,H}\n",
    "             (1/20, 2, +0.1 + fee),  # {1,H,L}\n",
    "             (9/20, 3, +0.1 + fee)   # {1,H,H}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# This environment implements the generic scenario of question 3 where for every stock\n",
    "# ri_H,ri_L are chosen uniformly in [-0.02, 0.1] and transition probabilities pi_HL, pi_LH\n",
    "# are equal to 0.1 for half the stocks and 0.5 for the other half.\n",
    "\n",
    "# Since every stock can have two price states, the number of total states in the MDP\n",
    "# we are creating will be = NumOfStoscks*2^numOfStocks\n",
    "\n",
    "\n",
    "def decimal_to_binary_array(decimal, length):\n",
    "\n",
    "    # Convert decimal to binary string (strip '0b' prefix)\n",
    "    binary_string = bin(decimal)[2:]\n",
    "\n",
    "    # Determine padding length\n",
    "    padding_length = max(0, length - len(binary_string))\n",
    "\n",
    "    # Pad binary string with leading zeros if needed\n",
    "    padded_binary_string = '0' * padding_length + binary_string\n",
    "\n",
    "    # Convert padded binary string to list of binary digits\n",
    "    binary_array = [int(bit) for bit in padded_binary_string]\n",
    "\n",
    "    return binary_array\n",
    "\n",
    "\n",
    "# Function that generates the environment of N stocks dynamically, with a transaction fee\n",
    "def generate_environment(N,fee):\n",
    "\n",
    "    states_for_each_stock = 2**N\n",
    "    total_states = N * states_for_each_stock\n",
    "    max_state_length = N\n",
    "\n",
    "    P = {}\n",
    "    pi = []\n",
    "    #Creating transition probabilities for the keep action\n",
    "    #of EACH stock\n",
    "    for i in range(0,N):\n",
    "        if(i < N/2):\n",
    "            # pi_HL = pi_LH = 0.1 | # pi_HH = pi_LL = 0.9\n",
    "            row = [0.9,0.1,0.1,0.9] #[LL,LH,HL,HH]\n",
    "        else:\n",
    "            # pi_HL = pi_LH = 0.5 | # pi_HH = pi_LL = 0.5\n",
    "            row = [0.5,0.5,0.5,0.5] #[LL,LH,HL,HH]\n",
    "        pi.append(row)\n",
    "\n",
    "    progress_bar = tqdm(range(0, total_states))\n",
    "    for i in progress_bar:\n",
    "        SubDictionary={}\n",
    "        action_Keep = []\n",
    "        action_Switch = []\n",
    "\n",
    "        # find what stock we are reffering to\n",
    "        # Stock ids start from 0\n",
    "        stock = i // states_for_each_stock\n",
    "\n",
    "        ##########################\n",
    "        # We define states of L and H with binary ids\n",
    "        # For example for 2 stocks this translation occurs:\n",
    "        # LL -> 0,0 -> 0\n",
    "        # LH -> 0,1 -> 1\n",
    "        # HL -> 1,0 -> 2\n",
    "        # HH -> 1,1 -> 3\n",
    "        # The binary ids are then translated to decimals so that\n",
    "        # we can use them in code\n",
    "        ##########################\n",
    "\n",
    "        current_state = i - stock * states_for_each_stock # find where this specific stock starts at the total_states environment\n",
    "                                                          # this is necessary to calculate the transition probabilities\n",
    "        # Convert decimal to binary string\n",
    "        # Convert the binary string to a list of integers (0s and 1s)\n",
    "        curr_state_array = decimal_to_binary_array(current_state, max_state_length)\n",
    "        # We can now use the array to find if each stock is in high (1s) or low (0s) state\n",
    "        # So We now know that we are at state {x,L,L,H....,H} with x the number of current stock\n",
    "\n",
    "        #__Keep Stock ________________________________________________________________________________________________________________\n",
    "        for j in range (stock*2**N, ((stock+1)*2**N)): # for every possible transition when keeping the same stock\n",
    "            state_to_trans = j - stock * states_for_each_stock          # value (H or L) of all of the stocks at the state we will transition to, in decimal form (0,1,2,3...)\n",
    "            trans_state_array = decimal_to_binary_array(state_to_trans, max_state_length) # convert to binary and take each bit separately (0 for L and 1 for H)\n",
    "    \n",
    "            transitionProb = 1\n",
    "\n",
    "            for k in range(len(trans_state_array)):\n",
    "                stock_state_trans = trans_state_array[k]  # 0 or 1 // low or high\n",
    "                stock_state_current = curr_state_array[k] # 0 or 1 // low or high\n",
    "\n",
    "                if(stock_state_current == 0 and stock_state_trans == 0):       # Pi_LL\n",
    "                    transitionProb = transitionProb * pi[stock][0]\n",
    "                elif(stock_state_current == 0 and stock_state_trans == 1):     # pi_LH\n",
    "                    transitionProb = transitionProb * pi[stock][1]\n",
    "                elif(stock_state_current == 1 and stock_state_trans == 0):     # pi_HL\n",
    "                    transitionProb = transitionProb * pi[stock][2]\n",
    "                else:                                                          # pi_HH\n",
    "                    transitionProb = transitionProb * pi[stock][3]\n",
    "            nextState = j\n",
    "\n",
    "            reward = random.uniform(-0.02, 0.1)\n",
    "            action_Keep.append((transitionProb,nextState,reward))\n",
    "            #print(\"\\nSWITCH\\n\")\n",
    "\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        #fee = 0\n",
    "        #__Switch Stock ________________________________________________________________________________________________________________\n",
    "        # progress_bar = tqdm(range (0, total_states))\n",
    "        for j in range (0, total_states): # for every possible transition \n",
    "            trans_stock = j // states_for_each_stock\n",
    "            \n",
    "            \n",
    "            if(trans_stock == stock):     # check if the transition stock is the same as the stock we start from\n",
    "                continue                  # we have already handle this situation above so we move on\n",
    "\n",
    "            trans_state = j - trans_stock * states_for_each_stock\n",
    "\n",
    "            trans_state_array = decimal_to_binary_array(trans_state, max_state_length)\n",
    "\n",
    "            transitionProb = 1\n",
    "\n",
    "            for k in range(len(trans_state_array)):\n",
    "\n",
    "                stock_state_trans = trans_state_array[k] # 0 or 1 // low or high\n",
    "                stock_state_current = curr_state_array[k] # 0 or 1 // low or high\n",
    "\n",
    "                if(stock_state_current == 0 and stock_state_trans == 0):       # Pi_LL\n",
    "                    transitionProb = transitionProb * pi[stock][0]\n",
    "\n",
    "                elif(stock_state_current == 0 and stock_state_trans == 1):     # pi_LH\n",
    "                    transitionProb = transitionProb * pi[stock][1]\n",
    "\n",
    "                elif(stock_state_current == 1 and stock_state_trans == 0):     # pi_HL\n",
    "                    transitionProb = transitionProb * pi[stock][2]\n",
    "\n",
    "                else:                                                          # pi_HH\n",
    "                    transitionProb = transitionProb * pi[stock][3]\n",
    "\n",
    "\n",
    "            nextState = j\n",
    "\n",
    "            reward = random.uniform(-0.02, 0.1) - fee\n",
    "            action_Switch.append((transitionProb*(1/(N-1)),nextState,reward))\n",
    "            \n",
    "\n",
    "        #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        SubDictionary[action_keep] = action_Keep\n",
    "        SubDictionary[action_switch] = action_Switch\n",
    "        P[i]=SubDictionary\n",
    "\n",
    "\n",
    "\n",
    "    return P\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1, Policy Evaluation/Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def policy_evaluation(pi, P, gamma = 1.0, epsilon = 1e-10):  #inputs: (1) policy to be evaluated, (2) model of the environment (transition probabilities, etc., see previous cell), (3) discount factor (with default = 1), (4) convergence error (default = 10^{-10})\n",
    "    #print(\"in policy EVALUATION\")\n",
    "    t = 0   #there's more elegant ways to do this\n",
    "    prev_V = np.zeros(len(P)) # use as \"cost-to-go\", i.e. for V(s')\n",
    "    while True:\n",
    "        V = np.zeros(len(P)) # current value function to be learnerd\n",
    "        for s in range(len(P)):  # do for every state\n",
    "            for prob, next_state, reward in P[s][pi(s)]:  # calculate one Bellman step --> i.e., sum over all probabilities of transitions and reward for that state, the action suggested by the (fixed) policy, the reward earned (dictated by the model), and the cost-to-go from the next state (which is also decided by the model)\n",
    "                V[s] = np.int64(V[s] + prob * (reward + gamma * prev_V[next_state]))\n",
    "        if np.max(np.abs(prev_V - V)) < epsilon: #check if the new V estimate is close enough to the previous one;     \n",
    "            break # if yes, finish loop\n",
    "        prev_V = V.copy() #freeze the new values (to be used as the next V(s'))\n",
    "        t += 1\n",
    "    return V\n",
    "\n",
    "\n",
    "def policy_improvement(V, P, gamma=1.0):  # takes a value function (as the cost to go V(s')), a model, and a discount parameter\n",
    "    #print(\"in policy IMPROVEMENT\")\n",
    "    Q = np.zeros((len(P), len(P[0])), dtype=np.float64) #create a Q value array\n",
    "    for s in range(len(P)):        # for every state in the environment/model\n",
    "        for a in range(len(P[s])):  # and for every action in that state\n",
    "            for prob, next_state, reward in P[s][a]:  #evaluate the action value based on the model and Value function given (which corresponds to the previous policy that we are trying to improve) \n",
    "                Q[s][a] += prob * (reward + gamma * V[next_state])\n",
    "    new_pi = lambda s: {s:a for s, a in enumerate(np.argmax(Q, axis=1))}[s]  # this basically creates the new (improved) policy by choosing at each state s the action a that has the highest Q value (based on the Q array we just calculated)\n",
    "    # lambda is a \"fancy\" way of creating a function without formally defining it (e.g. simply to return, as here...or to use internally in another function)\n",
    "    # you can implement this in a much simpler way, by using just a few more lines of code -- if this command is not clear, I suggest to try coding this yourself\n",
    "    \n",
    "    return new_pi,Q\n",
    "\n",
    "# policy iteration is simple, it will call alternatively policy evaluation then policy improvement, till the policy converges.\n",
    "\n",
    "def policy_iteration(P, gamma = 1.0, epsilon = 1e-10):\n",
    "    t = 0\n",
    "    random_actions = np.random.choice(tuple(P[0].keys()), len(P))     # start with random actions for each state  \n",
    "    pi = lambda s: {s:a for s, a in enumerate(random_actions)}[s]     # and define your initial policy pi_0 based on these action (remember, we are passing policies around as python \"functions\", hence the need for this second line)\n",
    "\n",
    "    while True:\n",
    "        old_pi = {s: pi(s) for s in range(len(P))}  #keep the old policy to compare with new\n",
    "        V = policy_evaluation(pi,P,gamma,epsilon)   #evaluate latest policy --> you receive its converged value function\n",
    "        pi,Q_table = policy_improvement(V,P,gamma)          #get a better policy using the value function of the previous one just calculated \n",
    "        \n",
    "        t += 1    \n",
    "        if old_pi == {s:pi(s) for s in range(len(P))}: # you have converged to the optimal policy if the \"improved\" policy is exactly the same as in the previous step\n",
    "            break\n",
    "    print('Converged after %d Policy Iterations' %t) #keep track of the number of (outer) iterations to converge\n",
    "    return V,pi,Q_table\n",
    "\n",
    "\n",
    "# Function to print policy\n",
    "def print_policy(policy, num_states=8):\n",
    "    for s in range(num_states):\n",
    "        print(f\"State {s}: Action {policy(s)}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions for Tubular Qlearning and DQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference_and_mse(q1, q2):\n",
    "    # Ensure the tables have the same dimensions\n",
    "    if len(q1) != len(q2) or any(len(row1) != len(row2) for row1, row2 in zip(q1, q2)):\n",
    "        raise ValueError(\"Both tables must have the same dimensions.\")\n",
    "    \n",
    "    result = []\n",
    "    total_squared_error = 0\n",
    "    num_elements = 0\n",
    "    \n",
    "    for row1, row2 in zip(q1, q2):\n",
    "        row_diff = []\n",
    "        for element1, element2 in zip(row1, row2):\n",
    "            diff = element1 - element2\n",
    "            row_diff.append(diff)\n",
    "            total_squared_error += diff ** 2\n",
    "            num_elements += 1\n",
    "        result.append(row_diff)\n",
    "    \n",
    "    mse = total_squared_error / num_elements\n",
    "    return result, mse\n",
    "\n",
    "\n",
    "def check_q_table_convergence(prev_Q, current_Q, epsilon=0.001):\n",
    "    \"\"\"\n",
    "    Checks if the Q-table has converged.\n",
    "\n",
    "    Parameters:\n",
    "    - prev_Q (np.ndarray): Previous Q-table.\n",
    "    - current_Q (np.ndarray): Current Q-table.\n",
    "    - epsilon (float): Convergence threshold.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if Q-table has converged, False otherwise.\n",
    "    \"\"\"\n",
    "    if prev_Q is None:\n",
    "        return False  # Cannot determine convergence without a previous Q-table\n",
    "    \n",
    "    # Calculate the maximum absolute difference between corresponding Q-values\n",
    "    max_diff = np.max(np.abs(prev_Q - current_Q))\n",
    "    \n",
    "    # Check if the maximum difference is less than epsilon\n",
    "    if max_diff < epsilon:\n",
    "        return True  # Q-table has converged\n",
    "    \n",
    "    return False  # Q-table has not converged yet\n",
    "\n",
    "\n",
    "# This function is used to simulate the environments response\n",
    "# It gets as input the environment, the current state and the action that we have selected\n",
    "# and it returns the next state and the reward\n",
    "def get_response(environment, state, action):\n",
    "    P = environment\n",
    "    response = P[state][action] # get next states, transition probabilities and transaction rewards\n",
    "                                # based on the current state and the action we want to make   \n",
    "\n",
    "\n",
    "    # we use random.choices to get a random next state based on the weighted probabilities of the next states\n",
    "    probabilities = []\n",
    "    avail_choices = range(len(P[state][action]))\n",
    "    # print(\"Choises = \",avail_choices)\n",
    "    # print(\"i in range \",len(P[state][action]))\n",
    "    for i in range(len(P[state][action])): \n",
    "        probabilities.append(response[i][0])\n",
    "\n",
    "\n",
    "    # because depending on the action (keep or switch) the num of actions we can take is different\n",
    "    # hence, we check what the action we do is and declare the choices array accordingly\n",
    "        \n",
    "    # Make a random choice based on probabilities\n",
    "    # k=1: Specifies that we want to make a single random choice.\n",
    "    # [0] is used to extract the single element from that list\n",
    "    random_choice = random.choices(avail_choices, weights=probabilities, k=1)[0]\n",
    "    #print(random_choice)\n",
    "    next_state = response [random_choice][1] # get next state\n",
    "    reward = response [random_choice][2]     # get reward\n",
    "\n",
    "    return next_state,reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2\n",
    " Implementing Tubular Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================================================================\n",
    "#################### Q-Learning ################\n",
    "#===== Hyperparameters ===================\n",
    "# alpha -> Learning rate\n",
    "# gamma -> Discount factor\n",
    "# epsilon ->  # Exploration rate\n",
    "# epsilon_decay -> Decay rate for epsilon\n",
    "# min_epsilon -> Minimum epsilon value\n",
    "# num_episodes -> Number of episodes\n",
    "\n",
    "def implement_Q_learning(env, num_of_episodes, alpha, gamma, epsilon_decay=0.999, alpha_decay=0.001, finding_parameters=False):\n",
    "    # arrays to track the values of epsilon, alpha and rewards\n",
    "    epsilon_tracker = np.zeros(num_of_episodes+1)\n",
    "    alpha_tracker = np.zeros(num_of_episodes+1)\n",
    "    mean_rewards_per_episode = np.zeros(num_of_episodes+1)\n",
    "   \n",
    "    Q = np.zeros((len(env),len(env[0])))\n",
    "    epsilon = 1.0                # Exploration rate0\n",
    "    #epsilon_decay = 0.99        # Decay rate for epsilon\n",
    "    min_epsilon = 0.1            # Minimum epsilon value\n",
    "    #alpha_decay = 0.01\n",
    "    initial_alpha = alpha\n",
    "    min_alpha = 0.001\n",
    "    convergence_episode = float('inf')  # Initialize with a large number\n",
    "    conv_counter = 0\n",
    "\n",
    "    progress_bar = tqdm(range(num_of_episodes))\n",
    "\n",
    "    for episode in progress_bar: \n",
    "        prev_Q = np.copy(Q)\n",
    "\n",
    "        current_state = random.randint(0, len(env)-1) # select a random starting state\n",
    "        cumulative_episode_reward = 0\n",
    "        tmp_reward = []\n",
    "        \n",
    "        for _ in range(100):      # do 100 steps do get a feel for what happens in the environment\n",
    "            # decide if we are going to explore or to exploit based on the epsilon value\n",
    "            if random.uniform(0,1) < epsilon:\n",
    "                # Explore by picking a random action\n",
    "                action = random.choice([0,1])\n",
    "                #print(\"EXLORE ACTION: \",action)\n",
    "            else:\n",
    "                action = np.argmax(Q[current_state])\n",
    "\n",
    "            next_state,reward = get_response(env, current_state, action)\n",
    "            \n",
    "            Q[current_state,action] = Q[current_state,action] + alpha * (\n",
    "                reward + gamma * np.max(Q[next_state]) - Q[current_state,action]\n",
    "            )\n",
    "\n",
    "            current_state = next_state    \n",
    "            cumulative_episode_reward += reward\n",
    "            tmp_reward.append(reward)\n",
    "\n",
    "        # update the hyperparameters   \n",
    "        epsilon_tracker[episode] = epsilon\n",
    "        alpha_tracker[episode] = alpha  \n",
    "        mean_rewards_per_episode[episode] = np.mean(tmp_reward)\n",
    "\n",
    "        epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "        alpha = max(min_alpha, initial_alpha * np.exp(-alpha_decay * episode))\n",
    "\n",
    "        #print(\"epsilon: \",epsilon)\n",
    "        if finding_parameters == True and check_q_table_convergence(prev_Q, Q, epsilon=0.00002):\n",
    "            conv_counter += 1\n",
    "            if conv_counter > 2:  # Adjust convergence criteria based on your problem\n",
    "                # convergence_episode = min(convergence_episode, episode)\n",
    "                convergence_episode = episode\n",
    "                # print(\"prev_Q:\", prev_Q)\n",
    "                # print(\"Q:\", Q)\n",
    "                print(\"convergence_episode = \",convergence_episode)\n",
    "                # print(np.argmax(Q,axis=1))\n",
    "                conv_counter = 0\n",
    "                break\n",
    "\n",
    "\n",
    "    # convergence_episode = None\n",
    "    return Q, convergence_episode, mean_rewards_per_episode, epsilon_tracker, alpha_tracker\n",
    "\n",
    "\n",
    "\n",
    "# environment = P2\n",
    "# alpha = 0.5\n",
    "# gamma = 0\n",
    "# V_opt1,P_opt1,Q_opt = policy_iteration(environment,gamma)\n",
    "\n",
    "\n",
    "# Define objective function for Optuna\n",
    "# Optuna tries to minimise the output of the objective function by modifying the hyperparameters of the tubular q learning algorithm\n",
    "# The output of the function will be the mse of the policy found at convergence summed up with the number of steps it took to converge\n",
    "# Because finding a correct policy is more important then the number of steps, mse is (weighted) multiplied with 10^14 (so that it has greater impact on \n",
    "# the output of the objective function)\n",
    "def objective(trial):    \n",
    "    #environment = P2  # Define your environment here\n",
    "    num_of_episodes = 10000  # Adjust as needed\n",
    "    alpha = trial.suggest_float('alpha', 0.5, 0.9, log=True)\n",
    "    gamma = 0\n",
    "    epsilon_decay = trial.suggest_float('epsilon_decay', 0.95, 0.999)\n",
    "    alpha_decay = trial.suggest_float('alpha_decay', 0.001, 0.01)\n",
    "    finding_parameters = True    \n",
    "    Q, convergence_episode,_,_,_ = implement_Q_learning(environment, num_of_episodes, alpha, gamma, epsilon_decay, alpha_decay, finding_parameters)\n",
    "    print(np.argmax(Q,axis=1))\n",
    "    \n",
    "    # Return the inverse of convergence episode (maximize speed)\n",
    "    convergence_episode = convergence_episode if convergence_episode != float('inf') else 10000\n",
    "    r, mse = calculate_difference_and_mse(Q_opt, Q)   \n",
    "    difference_count = sum(1 for x, y in zip(np.argmax(Q_opt,axis=1), np.argmax(Q,axis=1)) if x != y)\n",
    "    result = mse * 10000000000000000 * (difference_count+1) + convergence_episode/10 \n",
    "    print(\"mse: \",mse,\" result: \", result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def count_tables_differences(table1, table2):\n",
    "    if len(table1) != len(table2):\n",
    "        raise ValueError(\"Both tables must have the same length.\")\n",
    "    \n",
    "    difference_count = sum(1 for x, y in zip(table1, table2) if x != y)\n",
    "    return difference_count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Deep Q-Learning Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################____TASK3____########################################\n",
    "\n",
    "# Define memory for Experience Replay\n",
    "class ReplayMemory():\n",
    "    def __init__(self, maxlen):\n",
    "        self.memory = deque([], maxlen=maxlen)\n",
    "    \n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        return random.sample(self.memory, sample_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "# Define model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_states, h1_nodes, out_actions):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define network layers\n",
    "        self.fc1 = nn.Linear(in_states, h1_nodes)   # first fully connected layer\n",
    "        self.out = nn.Linear(h1_nodes, out_actions) # output layer w\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) # Apply rectified linear unit (ReLU) activation\n",
    "        x = self.out(x)         # Calculate output\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Class That Implements Our Deep Q-Network\n",
    "class stock_market_trading_DQN():    \n",
    "    # HyperParameters\n",
    "    alpha = 0.001              # Learning rate\n",
    "    gamma = 0              # Discount Factor\n",
    "    synching_period = 100    # After this many batches we synch the target nn with the policy nn\n",
    "    replay_buffer_size = 10000 # Size of replay buffer\n",
    "    min_batch_size = 64      # Size of each batch\n",
    "    #optimizer = optim.Adam(q_network.parameters(), lr=0.001)\n",
    "\n",
    "    # Define Huber as our loss function\n",
    "    # loss_func = nn.SmoothL1Loss()\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = None\n",
    "    ACTIONS = [0,1]\n",
    "    num_actions = 2\n",
    "    \n",
    "    # Encode the input state \n",
    "    def state_to_dqn_input(self, state:int, num_states:int)->torch.Tensor:\n",
    "        input_tensor = torch.zeros(num_states)\n",
    "        input_tensor[state] = 1\n",
    "        return input_tensor\n",
    "            \n",
    "    # This method is responsible to train our network based on a number of 'episodes'\n",
    "    def train_DQN(self, episodes,environment,gamma,lr):\n",
    "        P = environment\n",
    "        num_of_states = len(P)\n",
    "        num_of_actions = len(P[0])\n",
    "        \n",
    "        mean_rewards_per_episode = np.zeros(episodes+1)\n",
    "\n",
    "        epsilon = 1 # Exploration rate\n",
    "        self.gamma = gamma\n",
    "        self.alpha = lr\n",
    "        memory_buffer = ReplayMemory(self.replay_buffer_size)\n",
    "        #memory_buffer = [[] for _ in range(self.replay_buffer_size)] \n",
    "        \n",
    "        #memory_buffer[i % 1000] = [0,1,2,3]\n",
    "        \n",
    "        # Create policy and target network. Number of nodes in the hidden layer can be adjusted.\n",
    "        # We create a NN with num of input nodes equal to the num of the total states \n",
    "        # The num of output layer nodes is equal to the num of the total actions\n",
    "        # The hidden layer's num of nodes is equal to the num of states -> this is adjustable\n",
    "        policy_dqn = DQN(in_states=num_of_states, h1_nodes=num_of_states, out_actions=num_of_actions)\n",
    "        target_dqn = DQN(in_states=num_of_states, h1_nodes=num_of_states, out_actions=num_of_actions)\n",
    "\n",
    "        # initialize the 2 networks to be the same \n",
    "        target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "\n",
    "        # print('Policy (random, before training):')\n",
    "        # self.print_dqn(policy_dqn)\n",
    "        # print('===============================================================')\n",
    "        # print('===============================================================')\n",
    "\n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        \n",
    "        # self.optimizer = torch.optim.RMSprop(policy_dqn.parameters(), lr=self.alpha, alpha=0.99, \n",
    "        #                                      eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(policy_dqn.parameters(), lr=self.alpha)\n",
    "        # optimizer = SGD([parameter], lr=0.1)\n",
    "        \n",
    "        # keep track of the reward at each round \n",
    "        reward_tracking = np.zeros(episodes)\n",
    "        # List to keep track of epsilon decay\n",
    "        epsilon_tracking = []\n",
    "        synch_counter = 0 # which step we are on \n",
    "        \n",
    "        progress_bar = tqdm(range(episodes))\n",
    "        for i in progress_bar:\n",
    "            current_state = random.randint(0, len(P)-1) # select a random starting state\n",
    "            tmp_reward = []\n",
    "\n",
    "            for _ in range(100):      # do 100 steps do get a feel for what happens in the environment\n",
    "                # decide if we are going to explore or to exploit based on the epsilon value\n",
    "                # if random.uniform(0,1) < epsilon:\n",
    "                if random.random() < epsilon:\n",
    "                    #action = np.random.binomial(1,0.5)     # Explore by picking a random action\n",
    "                    action = random.choice([0,1])\n",
    "                else:\n",
    "                     # From the output layer, choose the node output (action) with the maximum value\n",
    "                    with torch.no_grad():\n",
    "                        action = policy_dqn(self.state_to_dqn_input(current_state, num_of_states)).argmax().item()\n",
    "                    \n",
    "                # get the response from the environment\n",
    "                next_state,reward = get_response(P, current_state, action)\n",
    "                # reward_tracking[i] = reward\n",
    "                \n",
    "                # Store the environments response into our memory        \n",
    "                # memory_buffer[step % 1000] = [current_state, action, next_state, reward]\n",
    "                memory_buffer.append((current_state, action, next_state, reward)) \n",
    "            \n",
    "                # update the next state\n",
    "                current_state = next_state    \n",
    "            \n",
    "                # Increment step counter\n",
    "                synch_counter += 1\n",
    "                tmp_reward.append(reward)\n",
    "            # Perform the optimization\n",
    "            if(len(memory_buffer) > self.min_batch_size):\n",
    "\n",
    "                #mini_batch = self.sample_mem_buffer(memory_buffer, self.min_batch_size)\n",
    "                mini_batch = memory_buffer.sample(self.min_batch_size)\n",
    "                self.optimize(mini_batch, policy_dqn, target_dqn)        \n",
    "\n",
    "                # Decay epsilon\n",
    "                epsilon = max(epsilon - 1/episodes, 0)\n",
    "                #epsilon = max(epsilon * 0.99, 0.1)\n",
    "\n",
    "                # Copy policy network to target network after a certain number of steps\n",
    "                ### CHECK\n",
    "                # if (step % self.synching_period) == 0:\n",
    "                if synch_counter > self.synching_period :\n",
    "                # if (synch_counter  self.synching_period): \n",
    "                    target_dqn.load_state_dict(policy_dqn.state_dict())\n",
    "                    synch_counter = 0\n",
    "                #tmp_reward += reward\n",
    "            mean_rewards_per_episode[i] = np.mean(tmp_reward)\n",
    "        # return the optimal policy\n",
    "        #return policy_dqn.state_dict()\n",
    "        torch.save(policy_dqn.state_dict(), \"frozen_lake_dql.pt\")\n",
    "        return policy_dqn,mean_rewards_per_episode\n",
    "                \n",
    "    def optimize(self,mini_batch, policy_dqn, target_dqn):\n",
    "        # Get number of input nodes\n",
    "        num_states = policy_dqn.fc1.in_features\n",
    "\n",
    "        current_q_list = []\n",
    "        target_q_list = []\n",
    "\n",
    "        for state, action, new_state, reward in mini_batch:\n",
    "            # Calculate target q value \n",
    "            # We disable the gradient tracking for memory optimization\n",
    "            with torch.no_grad():\n",
    "                # Here we get the optimal output we SHOULD have gotten according to the target NN\n",
    "                target = torch.FloatTensor(\n",
    "                    # For DQNs the target NNs parameters are modified according to the equation\n",
    "                    # Q[state,action] = reward + γ *max{Q[next_state]}\n",
    "                    reward + self.gamma * target_dqn(self.state_to_dqn_input(new_state, num_states)).max()\n",
    "                )\n",
    "                    \n",
    "            # Get the current set of Q values\n",
    "            current_q = policy_dqn(self.state_to_dqn_input(state, num_states))\n",
    "            current_q_list.append(current_q)\n",
    "\n",
    "            # Get the target set of Q values\n",
    "            target_q = target_dqn(self.state_to_dqn_input(state, num_states)) \n",
    "\n",
    "            # Adjust the specific action to the target that was just calculated\n",
    "            target_q[action] = target\n",
    "            target_q_list.append(target_q)\n",
    "\n",
    "        # calculate the loss for all the batch  \n",
    "        loss = self.loss_func(torch.stack(current_q_list), torch.stack(target_q_list))\n",
    "\n",
    "        # Optimize the model by running back-propagation\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        \n",
    "    # Test function\n",
    "    def test_DQN(self, episodes,environment):\n",
    "        # Create FrozenLake instance\n",
    "        P = environment\n",
    "        num_of_states = len(P)\n",
    "        num_of_actions = len(P[0])\n",
    "\n",
    "        # Load learned policy\n",
    "        policy_dqn = DQN(in_states=num_of_states, h1_nodes=num_of_states, out_actions=num_of_actions) \n",
    " \n",
    "        policy_dqn.load_state_dict(torch.load(\"frozen_lake_dql.pt\"))\n",
    "        policy_dqn.eval()    # switch model to evaluation mode\n",
    "\n",
    "        # print('Policy (trained):')\n",
    "        # self.print_dqn(policy_dqn)\n",
    "\n",
    "        for i in range(episodes):\n",
    "            current_state = random.randint(0, num_of_states-1)\n",
    "\n",
    "            for _ in range(100):\n",
    "                # Select best action   \n",
    "                with torch.no_grad():\n",
    "                    action = policy_dqn(self.state_to_dqn_input(current_state, num_of_states)).argmax().item()\n",
    "                # Execute action\n",
    "                current_state,reward = get_response(P, current_state, action)\n",
    "\n",
    "        \n",
    "        \n",
    "    def print_dqn(self, dqn):\n",
    "        # Get number of input nodes\n",
    "        num_states = dqn.fc1.in_features\n",
    "        Q_table = np.zeros((num_states, self.num_actions))\n",
    "\n",
    "        # Loop each state and print policy to console\n",
    "        for s in range(num_states):\n",
    "\n",
    "            q_values_element = dqn(self.state_to_dqn_input(s, num_states)).tolist()\n",
    "            Q_table[s] = q_values_element\n",
    "            \n",
    "            #  Format q values for printing\n",
    "            q_values = ''\n",
    "            for q in dqn(self.state_to_dqn_input(s, num_states)).tolist():\n",
    "                q_values += \"{:+.2f}\".format(q)+' '  # Concatenate q values, format to 2 decimals\n",
    "            q_values=q_values.rstrip()              # Remove space at the end\n",
    "            #\n",
    "\n",
    "            # Map the best action\n",
    "            best_action = dqn(self.state_to_dqn_input(s, num_states)).argmax()\n",
    "\n",
    "            # Print policy in the format of: state, action, q values\n",
    "            # The printed layout matches the FrozenLake map.\n",
    "            print(f'{s:02},{best_action},[{q_values}]', end='\\n')         \n",
    "            if (s+1)%4==0:\n",
    "                print() # Print a newline every 4 states\n",
    "            \n",
    "        #Q_table_transposed = [list(row) for row in zip(*Q_table)]\n",
    "        return Q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna study for DQN (hyperparameter auto-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     # Hyperparameters to tune\n",
    "#     alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
    "#     # gamma = trial.suggest_uniform('gamma', 0.8, 1.0)\n",
    "#     gamma = 0\n",
    "#     synching_period = trial.suggest_int('synching_period', 50, 500)\n",
    "#     replay_buffer_size = trial.suggest_int('replay_buffer_size', 1000, 20000)\n",
    "#     min_batch_size = trial.suggest_int('min_batch_size', 32, 256)\n",
    "    \n",
    "#     # Create an instance of the stock_market_trading_DQN class\n",
    "#     dqn_agent = stock_market_trading_DQN()\n",
    "    \n",
    "#     # Dummy environment\n",
    "#     num_states = 16\n",
    "#     num_actions = 2\n",
    "#     P = np.random.rand(num_states, num_actions)\n",
    "    \n",
    "#     # Train the DQN with the given hyperparameters\n",
    "#     trained_policy = dqn_agent.train_DQN(\n",
    "#         episodes=500,\n",
    "#         environment=P,\n",
    "#         gamma=gamma,\n",
    "#         lr=alpha\n",
    "#     )\n",
    "    \n",
    "#     # Test the trained DQN\n",
    "#     total_reward = 0\n",
    "#     for _ in range(10):  # Run multiple episodes for evaluation\n",
    "#         current_state = random.randint(0, len(P) - 1)\n",
    "#         for _ in range(100):  # Steps in an episode\n",
    "#             with torch.no_grad():\n",
    "#                 action = trained_policy(dqn_agent.state_to_dqn_input(current_state, num_states)).argmax().item()\n",
    "#             current_state, reward = get_response(P, current_state, action)\n",
    "#             total_reward += reward\n",
    "    \n",
    "#     # Return the total reward as the objective to maximize\n",
    "#     return total_reward\n",
    "\n",
    "# # Create a study and optimize the objective function\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)\n",
    "\n",
    "# print('Best hyperparameters: ', study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:00<00:00, 542.50it/s] \n"
     ]
    }
   ],
   "source": [
    "#environment = P1\n",
    "environment = P2\n",
    "environment = generate_environment(6,0.01)\n",
    "#print(environment)\n",
    "gamma = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Optimal Policy (policy Iteration -> Ground Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 2 Policy Iterations\n",
      "Optial Policy From Policy Iteration (Phase 1)\n",
      "[0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0\n",
      " 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "V_opt1,P_opt1,Q_opt = policy_iteration(environment,gamma)\n",
    "print(\"Optial Policy From Policy Iteration (Phase 1)\")\n",
    "print(np.argmax(Q_opt,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Tubular Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-19 12:21:17,943] A new study created in memory with name: no-name-aed3daa4-d4a4-430d-ab44-e9655ebe4d9c\n",
      "100%|██████████| 10000/10000 [00:13<00:00, 766.70it/s]\n",
      "[I 2024-07-19 12:21:30,991] Trial 0 finished with value: 21525365865862.66 and parameters: {'alpha': 0.8491480952162173, 'epsilon_decay': 0.9549591186727926, 'alpha_decay': 0.0032907786217611468}. Best is trial 0 with value: 21525365865862.66.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0\n",
      " 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "mse:  5.9792682957951836e-05  result:  21525365865862.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 529.72it/s]\n",
      "[I 2024-07-19 12:21:49,873] Trial 1 finished with value: 117803632232204.16 and parameters: {'alpha': 0.6837496796823592, 'epsilon_decay': 0.9510459635789111, 'alpha_decay': 0.009990769823757982}. Best is trial 0 with value: 21525365865862.66.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0\n",
      " 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "mse:  0.0001613748386728824  result:  117803632232204.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 555.18it/s]\n",
      "[I 2024-07-19 12:22:07,888] Trial 2 finished with value: 46880849064679.266 and parameters: {'alpha': 0.5796036659876925, 'epsilon_decay': 0.9679858750535418, 'alpha_decay': 0.0055319756602190805}. Best is trial 0 with value: 21525365865862.66.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "mse:  8.845443219562126e-05  result:  46880849064679.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:17<00:00, 574.37it/s]\n",
      "[I 2024-07-19 12:22:25,303] Trial 3 finished with value: 8373735546067.86 and parameters: {'alpha': 0.5001597012746284, 'epsilon_decay': 0.9962564903363987, 'alpha_decay': 0.0018397388485616173}. Best is trial 3 with value: 8373735546067.86.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0\n",
      " 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "mse:  2.8874950155406416e-05  result:  8373735546067.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:16<00:00, 590.73it/s]\n",
      "[I 2024-07-19 12:22:42,235] Trial 4 finished with value: 4203272591186.6885 and parameters: {'alpha': 0.7717161320807497, 'epsilon_decay': 0.9854738270297675, 'alpha_decay': 0.0012959530099072118}. Best is trial 4 with value: 4203272591186.6885.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0\n",
      " 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "mse:  2.101636295093344e-05  result:  4203272591186.6885\n",
      "Best hyperparameters:  {'alpha': 0.7717161320807497, 'epsilon_decay': 0.9854738270297675, 'alpha_decay': 0.0012959530099072118}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:26<00:00, 563.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 FINAL OPTIMAL POLICY [0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:24<00:00, 617.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 FINAL OPTIMAL POLICY [0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 1 1 1 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 0\n",
      " 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:29<00:00, 676.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0\n",
      " 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Tabular Q-Learnig Policy [0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 0\n",
      " 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Qopt = \n",
      " [[0.05628898 0.03925502]\n",
      " [0.0693186  0.02143849]\n",
      " [0.05944512 0.0366098 ]\n",
      " [0.05559298 0.04067889]\n",
      " [0.02062907 0.02745481]\n",
      " [0.01313807 0.0173452 ]\n",
      " [0.04911497 0.03718754]\n",
      " [0.06293295 0.01443758]\n",
      " [0.01119837 0.04096399]\n",
      " [0.01882785 0.03256808]\n",
      " [0.03404288 0.02027562]\n",
      " [0.06815747 0.03204   ]\n",
      " [0.04471635 0.02707122]\n",
      " [0.03459056 0.03190136]\n",
      " [0.06266718 0.02461965]\n",
      " [0.03287897 0.04066295]\n",
      " [0.06313888 0.02629414]\n",
      " [0.01939002 0.01419895]\n",
      " [0.03047787 0.02454402]\n",
      " [0.06915962 0.03705491]\n",
      " [0.0602981  0.02972048]\n",
      " [0.04874877 0.02858591]\n",
      " [0.03626344 0.03027669]\n",
      " [0.0479759  0.02053713]\n",
      " [0.05964311 0.01929412]\n",
      " [0.01956896 0.0311405 ]\n",
      " [0.06716298 0.02045444]\n",
      " [0.03199113 0.03589264]\n",
      " [0.04953439 0.0260072 ]\n",
      " [0.05635209 0.01960172]\n",
      " [0.01678246 0.02712133]\n",
      " [0.05458062 0.03794334]\n",
      " [0.04882917 0.03247659]\n",
      " [0.0632186  0.03173599]\n",
      " [0.02679715 0.02957703]\n",
      " [0.02310747 0.02045861]\n",
      " [0.04914501 0.02578823]\n",
      " [0.0599856  0.03537464]\n",
      " [0.06956715 0.02599338]\n",
      " [0.03957216 0.0175107 ]\n",
      " [0.02885094 0.04508294]\n",
      " [0.01960695 0.04231756]\n",
      " [0.0168301  0.01998255]\n",
      " [0.07106203 0.02857687]\n",
      " [0.05443114 0.02879264]\n",
      " [0.01615184 0.02724047]\n",
      " [0.04003722 0.03966462]\n",
      " [0.03720954 0.02398281]\n",
      " [0.04688983 0.0382763 ]\n",
      " [0.01819408 0.01658705]\n",
      " [0.06657012 0.03877382]\n",
      " [0.02406601 0.04197088]\n",
      " [0.0669213  0.03768009]\n",
      " [0.01349662 0.01747735]\n",
      " [0.06016081 0.01977817]\n",
      " [0.01471907 0.02302561]\n",
      " [0.03935115 0.0419479 ]\n",
      " [0.0325496  0.02097284]\n",
      " [0.05124468 0.02370002]\n",
      " [0.02113802 0.03044372]\n",
      " [0.01444332 0.03314761]\n",
      " [0.03047054 0.03223943]\n",
      " [0.01787849 0.01666457]\n",
      " [0.04339601 0.02515161]\n",
      " [0.05646769 0.03036841]\n",
      " [0.05132525 0.02704565]\n",
      " [0.03385949 0.03507724]\n",
      " [0.04478875 0.02457067]\n",
      " [0.01564301 0.02479331]\n",
      " [0.03215318 0.03461297]\n",
      " [0.02679547 0.02615618]\n",
      " [0.0353736  0.03496992]\n",
      " [0.01707561 0.02375555]\n",
      " [0.05966778 0.03933531]\n",
      " [0.05447361 0.02508825]\n",
      " [0.07097327 0.038446  ]\n",
      " [0.03039615 0.03042567]\n",
      " [0.04326171 0.05164529]\n",
      " [0.01238151 0.03481767]\n",
      " [0.06642554 0.02597568]\n",
      " [0.03932272 0.03364121]\n",
      " [0.0023885  0.04523113]\n",
      " [0.04379464 0.03343289]\n",
      " [0.06450339 0.01072937]\n",
      " [0.05292698 0.03629028]\n",
      " [0.06531874 0.02876777]\n",
      " [0.05895465 0.03290663]\n",
      " [0.01853709 0.02618402]\n",
      " [0.06190284 0.03532445]\n",
      " [0.05601836 0.03236077]\n",
      " [0.0251868  0.01773555]\n",
      " [0.04649866 0.02323567]\n",
      " [0.01224441 0.02639059]\n",
      " [0.04404799 0.02653406]\n",
      " [0.00806386 0.02225015]\n",
      " [0.02765396 0.04254355]\n",
      " [0.049747   0.02212412]\n",
      " [0.03903799 0.02992606]\n",
      " [0.02243516 0.03294377]\n",
      " [0.05042717 0.05168164]\n",
      " [0.01508947 0.04557485]\n",
      " [0.0387766  0.02125382]\n",
      " [0.0415467  0.03343031]\n",
      " [0.0077974  0.03590045]\n",
      " [0.04191042 0.02851485]\n",
      " [0.04138166 0.0384451 ]\n",
      " [0.04274488 0.01855102]\n",
      " [0.00305586 0.01709827]\n",
      " [0.01212098 0.02609686]\n",
      " [0.04257716 0.04652856]\n",
      " [0.03002605 0.01974015]\n",
      " [0.06937247 0.03156428]\n",
      " [0.07295162 0.0296445 ]\n",
      " [0.02736069 0.0353479 ]\n",
      " [0.0532058  0.02260095]\n",
      " [0.01894249 0.02239113]\n",
      " [0.04693578 0.0459355 ]\n",
      " [0.056152   0.02188779]\n",
      " [0.05081212 0.03082705]\n",
      " [0.05304334 0.02254663]\n",
      " [0.06090702 0.04582278]\n",
      " [0.03522132 0.02711181]\n",
      " [0.02544307 0.02431928]\n",
      " [0.07243834 0.03078131]\n",
      " [0.04640046 0.0243044 ]\n",
      " [0.04529637 0.03409635]\n",
      " [0.0410171  0.04307524]\n",
      " [0.03991179 0.04186448]\n",
      " [0.07454309 0.03605666]\n",
      " [0.04217039 0.02756642]\n",
      " [0.07136853 0.0301345 ]\n",
      " [0.06383378 0.03162894]\n",
      " [0.04093168 0.03278092]\n",
      " [0.07396226 0.02343157]\n",
      " [0.03926411 0.04060089]\n",
      " [0.01355052 0.03535387]\n",
      " [0.01137376 0.03654481]\n",
      " [0.04877151 0.03195076]\n",
      " [0.02627676 0.03430433]\n",
      " [0.0049262  0.03685863]\n",
      " [0.05944149 0.04187271]\n",
      " [0.03854778 0.02689162]\n",
      " [0.01429534 0.04036118]\n",
      " [0.05816945 0.02684366]\n",
      " [0.03296824 0.04521195]\n",
      " [0.06149065 0.03501259]\n",
      " [0.02794126 0.02858321]\n",
      " [0.06281041 0.01194506]\n",
      " [0.00220232 0.03123269]\n",
      " [0.05577095 0.03237885]\n",
      " [0.07180392 0.0252878 ]\n",
      " [0.01681684 0.02511708]\n",
      " [0.0427637  0.01299452]\n",
      " [0.06061325 0.02161082]\n",
      " [0.02135204 0.04176839]\n",
      " [0.05523908 0.0230493 ]\n",
      " [0.01320706 0.03390285]\n",
      " [0.03454636 0.01809011]\n",
      " [0.04705573 0.04266009]\n",
      " [0.07029535 0.02270874]\n",
      " [0.01459762 0.03203919]\n",
      " [0.01925308 0.02065675]\n",
      " [0.02765268 0.03426021]\n",
      " [0.05760238 0.03524966]\n",
      " [0.0242479  0.0140428 ]\n",
      " [0.06270967 0.02018775]\n",
      " [0.06253321 0.01484687]\n",
      " [0.02352115 0.03100177]\n",
      " [0.06087081 0.02896048]\n",
      " [0.0408642  0.03789358]\n",
      " [0.01788368 0.03118372]\n",
      " [0.03329057 0.0427016 ]\n",
      " [0.06182698 0.02409436]\n",
      " [0.03545905 0.02870234]\n",
      " [0.01609023 0.02279756]\n",
      " [0.06255661 0.02066645]\n",
      " [0.07179577 0.02660215]\n",
      " [0.02382419 0.02505026]\n",
      " [0.00959429 0.04375469]\n",
      " [0.01791515 0.02679169]\n",
      " [0.04107182 0.00967629]\n",
      " [0.0253119  0.01669282]\n",
      " [0.03674995 0.02143284]\n",
      " [0.01634338 0.03227819]\n",
      " [0.0332981  0.03531105]\n",
      " [0.05400114 0.030707  ]\n",
      " [0.04517897 0.03188288]\n",
      " [0.01745427 0.02081877]\n",
      " [0.01150877 0.02501193]\n",
      " [0.00961399 0.02870692]\n",
      " [0.01505472 0.02622352]\n",
      " [0.04507435 0.03965002]\n",
      " [0.04535477 0.03322145]\n",
      " [0.04038564 0.03001984]\n",
      " [0.03423187 0.02764332]\n",
      " [0.0329985  0.02967188]\n",
      " [0.03829048 0.0309621 ]\n",
      " [0.04122113 0.02671222]\n",
      " [0.0400342  0.02932967]\n",
      " [0.04077953 0.03209938]\n",
      " [0.04077433 0.0266257 ]\n",
      " [0.03916296 0.03048122]\n",
      " [0.03907476 0.03079695]\n",
      " [0.04076635 0.03104801]\n",
      " [0.032314   0.03406477]\n",
      " [0.04021749 0.03374742]\n",
      " [0.03817017 0.02971273]\n",
      " [0.04215228 0.02823381]\n",
      " [0.04344357 0.03000624]\n",
      " [0.03924636 0.03398759]\n",
      " [0.04062614 0.03126701]\n",
      " [0.03910206 0.03083917]\n",
      " [0.04190668 0.03077056]\n",
      " [0.03310913 0.02986801]\n",
      " [0.04461712 0.03419729]\n",
      " [0.0471824  0.02976819]\n",
      " [0.03732666 0.0317979 ]\n",
      " [0.04361947 0.03246416]\n",
      " [0.04172832 0.02737474]\n",
      " [0.0400859  0.03027118]\n",
      " [0.04626551 0.03131294]\n",
      " [0.03498218 0.02975468]\n",
      " [0.03866652 0.0313119 ]\n",
      " [0.03812533 0.03194771]\n",
      " [0.03831982 0.02896597]\n",
      " [0.04386705 0.03111615]\n",
      " [0.03604981 0.02939621]\n",
      " [0.04054857 0.0312693 ]\n",
      " [0.03853556 0.02764586]\n",
      " [0.0443635  0.02967642]\n",
      " [0.03551078 0.03279314]\n",
      " [0.03496592 0.03187692]\n",
      " [0.03367265 0.03265419]\n",
      " [0.03013647 0.03184198]\n",
      " [0.0383227  0.03129804]\n",
      " [0.04906878 0.03013061]\n",
      " [0.03897435 0.03289434]\n",
      " [0.03912957 0.03032685]\n",
      " [0.042953   0.03266795]\n",
      " [0.04654005 0.02999685]\n",
      " [0.03006302 0.03112129]\n",
      " [0.04458377 0.02808297]\n",
      " [0.0466945  0.03138912]\n",
      " [0.03751665 0.02851475]\n",
      " [0.04090609 0.02931369]\n",
      " [0.04284902 0.02976807]\n",
      " [0.03983925 0.03101376]\n",
      " [0.03968735 0.02935455]\n",
      " [0.03777385 0.03093347]\n",
      " [0.03414045 0.02966247]\n",
      " [0.03993086 0.02720932]\n",
      " [0.03820941 0.03294672]\n",
      " [0.03998564 0.03330223]\n",
      " [0.03575789 0.03133084]\n",
      " [0.03877498 0.03240591]\n",
      " [0.04108835 0.02820297]\n",
      " [0.0376964  0.02843486]\n",
      " [0.03500034 0.03104324]\n",
      " [0.03440942 0.02928361]\n",
      " [0.0385972  0.02776686]\n",
      " [0.04257187 0.02808172]\n",
      " [0.03939616 0.02569452]\n",
      " [0.04122097 0.02772565]\n",
      " [0.03674128 0.02804126]\n",
      " [0.0374741  0.0269905 ]\n",
      " [0.03732753 0.0309948 ]\n",
      " [0.04292614 0.0313044 ]\n",
      " [0.04229636 0.03201725]\n",
      " [0.05028914 0.03265779]\n",
      " [0.04091364 0.02950899]\n",
      " [0.04162336 0.02848995]\n",
      " [0.04233808 0.02808383]\n",
      " [0.03645554 0.02851842]\n",
      " [0.03960996 0.02925766]\n",
      " [0.03186141 0.02997195]\n",
      " [0.04088471 0.02935218]\n",
      " [0.04096006 0.02761599]\n",
      " [0.03922031 0.02885178]\n",
      " [0.05150006 0.03024924]\n",
      " [0.03899449 0.02783315]\n",
      " [0.03868848 0.03201891]\n",
      " [0.04280147 0.03049298]\n",
      " [0.0442649  0.02881966]\n",
      " [0.04554848 0.03010338]\n",
      " [0.03762241 0.03128172]\n",
      " [0.03736562 0.02901956]\n",
      " [0.03513846 0.02584246]\n",
      " [0.03888463 0.02972596]\n",
      " [0.04984365 0.03160214]\n",
      " [0.04885519 0.03044685]\n",
      " [0.03648448 0.02874432]\n",
      " [0.03261171 0.0341326 ]\n",
      " [0.02932865 0.03124785]\n",
      " [0.04776024 0.02963076]\n",
      " [0.03274135 0.02896978]\n",
      " [0.03966075 0.02796513]\n",
      " [0.03933483 0.03164081]\n",
      " [0.03694767 0.03058857]\n",
      " [0.04407362 0.03027846]\n",
      " [0.04020676 0.02666901]\n",
      " [0.03123093 0.0284934 ]\n",
      " [0.04510905 0.02988576]\n",
      " [0.0479038  0.02846169]\n",
      " [0.03911188 0.03229576]\n",
      " [0.04008476 0.03235843]\n",
      " [0.04353979 0.02730584]\n",
      " [0.04440609 0.02941112]\n",
      " [0.03494435 0.02864352]\n",
      " [0.04433427 0.03009935]\n",
      " [0.04216801 0.03317731]\n",
      " [0.04095499 0.02942865]\n",
      " [0.04393509 0.02965503]\n",
      " [0.043783   0.03003064]\n",
      " [0.04100226 0.02744571]\n",
      " [0.04057664 0.03139409]\n",
      " [0.04049697 0.03118521]\n",
      " [0.02897706 0.02866315]\n",
      " [0.04389861 0.03078704]\n",
      " [0.03973792 0.02857531]\n",
      " [0.03798922 0.02997779]\n",
      " [0.03707011 0.02966052]\n",
      " [0.04569541 0.03240042]\n",
      " [0.02960205 0.02668612]\n",
      " [0.038134   0.02906955]\n",
      " [0.04052142 0.03015897]\n",
      " [0.03884349 0.03388434]\n",
      " [0.04000444 0.03005146]\n",
      " [0.04177308 0.03380974]\n",
      " [0.04082341 0.02622392]\n",
      " [0.03607128 0.02688945]\n",
      " [0.04494751 0.03041079]\n",
      " [0.03314469 0.02906239]\n",
      " [0.03801803 0.03109188]\n",
      " [0.0351439  0.02920351]\n",
      " [0.04009346 0.02888753]\n",
      " [0.03529197 0.03015958]\n",
      " [0.03645118 0.02875079]\n",
      " [0.04176218 0.03127567]\n",
      " [0.03834674 0.0339465 ]\n",
      " [0.04343452 0.02834418]\n",
      " [0.0433112  0.02770081]\n",
      " [0.04174456 0.03222616]\n",
      " [0.04153503 0.02742603]\n",
      " [0.03527024 0.03065045]\n",
      " [0.03965749 0.02903284]\n",
      " [0.04317261 0.03442968]\n",
      " [0.04569379 0.02866141]\n",
      " [0.04133673 0.03166999]\n",
      " [0.04634378 0.03478606]\n",
      " [0.04806239 0.0313957 ]\n",
      " [0.0421055  0.02677786]\n",
      " [0.03758405 0.02931119]\n",
      " [0.04155053 0.0262759 ]\n",
      " [0.04572957 0.03305467]\n",
      " [0.04645366 0.0252645 ]\n",
      " [0.0347728  0.02706117]\n",
      " [0.04334679 0.03112589]\n",
      " [0.04306563 0.03079677]\n",
      " [0.03761215 0.02978906]\n",
      " [0.03496931 0.03069176]\n",
      " [0.03884107 0.02994046]\n",
      " [0.04574549 0.02745179]\n",
      " [0.03833    0.03184456]\n",
      " [0.04324997 0.02833507]\n",
      " [0.04350973 0.02825205]\n",
      " [0.036645   0.02999247]\n",
      " [0.04676741 0.02703993]\n",
      " [0.04032746 0.02931339]\n",
      " [0.03788094 0.02790522]\n",
      " [0.03854234 0.02765638]\n",
      " [0.03207183 0.03052326]\n",
      " [0.04358235 0.03110876]\n",
      " [0.03674691 0.03120761]\n",
      " [0.03987754 0.02817284]\n",
      " [0.03670441 0.02912967]\n",
      " [0.03816091 0.02744917]\n",
      " [0.04612051 0.0296269 ]\n",
      " [0.03600834 0.02521   ]\n",
      " [0.04174627 0.03194349]\n",
      " [0.04185401 0.03101021]\n",
      " [0.03762235 0.02993898]\n",
      " [0.04804686 0.03470395]\n",
      " [0.04265531 0.03433936]\n",
      " [0.03771365 0.03060361]]\n",
      "Qtabular = \n",
      " [[ 0.05559502  0.03381822]\n",
      " [ 0.0684561   0.01705729]\n",
      " [ 0.05958902  0.03323999]\n",
      " [ 0.05546516  0.03793968]\n",
      " [ 0.0165359   0.02693287]\n",
      " [ 0.00766249  0.0177415 ]\n",
      " [ 0.04929433  0.03585129]\n",
      " [ 0.06205344  0.014149  ]\n",
      " [ 0.01068141  0.03946099]\n",
      " [ 0.01825123  0.03250194]\n",
      " [ 0.03367879  0.02206382]\n",
      " [ 0.06848059  0.03073396]\n",
      " [ 0.04525505  0.02489514]\n",
      " [ 0.03423092  0.02743732]\n",
      " [ 0.06313119  0.02447953]\n",
      " [ 0.01988982  0.03912008]\n",
      " [ 0.06112812  0.01821669]\n",
      " [ 0.01011448  0.01422168]\n",
      " [ 0.03082554  0.02269351]\n",
      " [ 0.06974398  0.03788068]\n",
      " [ 0.06060455  0.03212356]\n",
      " [ 0.04861739  0.02882215]\n",
      " [ 0.03702777  0.02759913]\n",
      " [ 0.04821629  0.02568161]\n",
      " [ 0.05979731  0.01390514]\n",
      " [ 0.0132557   0.0321914 ]\n",
      " [ 0.06555452  0.02392073]\n",
      " [ 0.03269033  0.03062931]\n",
      " [ 0.04958568  0.02725445]\n",
      " [ 0.05738294  0.01999656]\n",
      " [ 0.01653834  0.02882605]\n",
      " [ 0.05445849  0.03804958]\n",
      " [ 0.04802611  0.03654227]\n",
      " [ 0.06502477  0.02391391]\n",
      " [ 0.02624978  0.02165163]\n",
      " [ 0.02292073  0.01495369]\n",
      " [ 0.04945735  0.02565346]\n",
      " [ 0.06012367  0.03015511]\n",
      " [ 0.07069361  0.02835871]\n",
      " [ 0.03891599  0.01783591]\n",
      " [ 0.0306738   0.04427073]\n",
      " [ 0.01906665  0.04224115]\n",
      " [ 0.01278703  0.01989843]\n",
      " [ 0.07049422  0.03371436]\n",
      " [ 0.05358786  0.01547208]\n",
      " [ 0.01902105  0.02769767]\n",
      " [ 0.03198618  0.04125681]\n",
      " [ 0.03682294  0.01956624]\n",
      " [ 0.04745186  0.03482956]\n",
      " [ 0.01845246  0.0098339 ]\n",
      " [ 0.06574433  0.0424626 ]\n",
      " [ 0.02305281  0.04134712]\n",
      " [ 0.06729192  0.03146422]\n",
      " [ 0.00587166  0.01752832]\n",
      " [ 0.05926124  0.02322502]\n",
      " [ 0.00703061  0.02284948]\n",
      " [ 0.03994259  0.03244836]\n",
      " [ 0.0323623   0.01513919]\n",
      " [ 0.05116354  0.02872052]\n",
      " [ 0.01791696  0.02936395]\n",
      " [ 0.02102207  0.03283916]\n",
      " [ 0.03062544  0.02242403]\n",
      " [ 0.0174569   0.0142478 ]\n",
      " [ 0.04279358  0.03124516]\n",
      " [ 0.05515009  0.02485876]\n",
      " [ 0.05138508  0.02611203]\n",
      " [ 0.0341277   0.02529781]\n",
      " [ 0.04483528  0.0118725 ]\n",
      " [ 0.00354154  0.0221558 ]\n",
      " [ 0.03051671  0.02875207]\n",
      " [ 0.01713475  0.02687771]\n",
      " [ 0.02765613  0.03574214]\n",
      " [ 0.01488572  0.02440212]\n",
      " [ 0.0594763   0.04094771]\n",
      " [ 0.05470162  0.02328337]\n",
      " [ 0.0701755   0.03973036]\n",
      " [ 0.01810704  0.0321057 ]\n",
      " [ 0.04211787  0.0519582 ]\n",
      " [ 0.00527605  0.03567211]\n",
      " [ 0.06669204  0.02242233]\n",
      " [ 0.03996152  0.02751619]\n",
      " [ 0.00059514  0.04429791]\n",
      " [ 0.04307243  0.03010972]\n",
      " [ 0.06260326  0.0120226 ]\n",
      " [ 0.05347566  0.02598031]\n",
      " [ 0.06567894  0.02137614]\n",
      " [ 0.05813008  0.01963726]\n",
      " [ 0.01478341  0.02579712]\n",
      " [ 0.06204144  0.03481457]\n",
      " [ 0.05577887  0.03479369]\n",
      " [ 0.02517925  0.01743351]\n",
      " [ 0.04673322  0.02943388]\n",
      " [ 0.0114221   0.02635727]\n",
      " [ 0.04356293  0.02352771]\n",
      " [ 0.00393468  0.02145159]\n",
      " [ 0.01982707  0.04116104]\n",
      " [ 0.05016691  0.02207955]\n",
      " [ 0.03935256  0.03213912]\n",
      " [ 0.02241554  0.03070336]\n",
      " [ 0.03996377  0.05102596]\n",
      " [ 0.01621804  0.04520481]\n",
      " [ 0.0389465   0.01887632]\n",
      " [ 0.041177    0.03469321]\n",
      " [ 0.00506004  0.0361856 ]\n",
      " [ 0.04290413  0.02749848]\n",
      " [ 0.04127527  0.03512235]\n",
      " [ 0.04269596  0.01857896]\n",
      " [-0.00274269  0.01675428]\n",
      " [ 0.00458923  0.0272195 ]\n",
      " [ 0.04365421  0.03995617]\n",
      " [ 0.0308823   0.01827493]\n",
      " [ 0.06991626  0.04387504]\n",
      " [ 0.07259799  0.0224615 ]\n",
      " [ 0.02439259  0.03507214]\n",
      " [ 0.05315504  0.02367884]\n",
      " [ 0.01462103  0.02203727]\n",
      " [ 0.0466978   0.04303996]\n",
      " [ 0.05741054  0.01692937]\n",
      " [ 0.05105092  0.02810063]\n",
      " [ 0.05267473  0.03237437]\n",
      " [ 0.06158939  0.04669702]\n",
      " [ 0.03631277  0.02738763]\n",
      " [ 0.0186537   0.02427988]\n",
      " [ 0.07364208  0.02768832]\n",
      " [ 0.04699661  0.02326781]\n",
      " [ 0.0458038   0.03522534]\n",
      " [ 0.0328166   0.04149884]\n",
      " [ 0.03467252  0.04111107]\n",
      " [ 0.07456166  0.03046165]\n",
      " [ 0.04230082  0.02676313]\n",
      " [ 0.07129938  0.02669912]\n",
      " [ 0.06380011  0.02065179]\n",
      " [ 0.04109914  0.02857899]\n",
      " [ 0.07446299  0.02466927]\n",
      " [ 0.0330028   0.04118577]\n",
      " [ 0.00397254  0.03447699]\n",
      " [ 0.00860213  0.03603129]\n",
      " [ 0.04848885  0.0343322 ]\n",
      " [ 0.01898587  0.03514792]\n",
      " [ 0.00295232  0.03572873]\n",
      " [ 0.0593296   0.0439577 ]\n",
      " [ 0.03857709  0.02481016]\n",
      " [ 0.02861448  0.0394072 ]\n",
      " [ 0.05795742  0.02448813]\n",
      " [ 0.02883205  0.04572964]\n",
      " [ 0.06165737  0.03209674]\n",
      " [ 0.02071011  0.02765285]\n",
      " [ 0.06274797  0.02159061]\n",
      " [ 0.00326823  0.03124966]\n",
      " [ 0.05580191  0.02385648]\n",
      " [ 0.07313056  0.03255992]\n",
      " [ 0.0138202   0.02503864]\n",
      " [ 0.04315099  0.01191949]\n",
      " [ 0.06084416  0.01650614]\n",
      " [ 0.02183451  0.04399771]\n",
      " [ 0.05584681  0.01652682]\n",
      " [ 0.00980522  0.03446765]\n",
      " [ 0.03489914  0.01656722]\n",
      " [ 0.04711492  0.04440658]\n",
      " [ 0.06960173  0.01959316]\n",
      " [ 0.01735938  0.03218932]\n",
      " [ 0.01864031  0.01001831]\n",
      " [ 0.02851169  0.02565005]\n",
      " [ 0.05746866  0.03238379]\n",
      " [ 0.02448796  0.01022132]\n",
      " [ 0.06262829  0.0243479 ]\n",
      " [ 0.06296315  0.00941515]\n",
      " [ 0.02024035  0.03138379]\n",
      " [ 0.06114397  0.03236986]\n",
      " [ 0.03298387  0.03786205]\n",
      " [ 0.01762721  0.03020423]\n",
      " [ 0.03043777  0.04085896]\n",
      " [ 0.06219188  0.02176835]\n",
      " [ 0.0365737   0.01895505]\n",
      " [ 0.0113449   0.02379063]\n",
      " [ 0.06249853  0.01433831]\n",
      " [ 0.07153513  0.0233972 ]\n",
      " [ 0.02022228  0.02603765]\n",
      " [ 0.01311456  0.04259871]\n",
      " [ 0.0179811   0.02497627]\n",
      " [ 0.04076646  0.00489272]\n",
      " [ 0.02649636  0.01575706]\n",
      " [ 0.03707136  0.01410185]\n",
      " [ 0.01314211  0.03203276]\n",
      " [ 0.03228328  0.02406374]\n",
      " [ 0.05450319  0.02529773]\n",
      " [ 0.04558258  0.03268693]\n",
      " [ 0.00671538  0.02023332]\n",
      " [ 0.00139222  0.02557816]\n",
      " [ 0.00921589  0.02942982]\n",
      " [ 0.01742842  0.02900837]\n",
      " [ 0.03680285  0.03961388]\n",
      " [ 0.04633991  0.03216559]\n",
      " [ 0.04115619  0.03201589]\n",
      " [ 0.03344861  0.02945385]\n",
      " [ 0.03400849  0.02566692]\n",
      " [ 0.03755105  0.0291536 ]\n",
      " [ 0.04260853  0.0210818 ]\n",
      " [ 0.03920286  0.02742213]\n",
      " [ 0.04042792  0.0317844 ]\n",
      " [ 0.03980347  0.02614864]\n",
      " [ 0.03966528  0.02464753]\n",
      " [ 0.03796781  0.02686214]\n",
      " [ 0.04091526  0.02581756]\n",
      " [ 0.02997899  0.03378532]\n",
      " [ 0.04026517  0.03152885]\n",
      " [ 0.03814483  0.0294931 ]\n",
      " [ 0.04229955  0.02068564]\n",
      " [ 0.04358319  0.02362323]\n",
      " [ 0.04102433  0.03372942]\n",
      " [ 0.04150245  0.02471211]\n",
      " [ 0.03851232  0.02610297]\n",
      " [ 0.04138924  0.02617261]\n",
      " [ 0.03353191  0.02848801]\n",
      " [ 0.04408387  0.03510476]\n",
      " [ 0.04748283  0.02971695]\n",
      " [ 0.03561227  0.03190492]\n",
      " [ 0.0437765   0.0229648 ]\n",
      " [ 0.04259559  0.02215693]\n",
      " [ 0.03942608  0.02741511]\n",
      " [ 0.04650377  0.03171015]\n",
      " [ 0.0348985   0.02513447]\n",
      " [ 0.03975594  0.03155944]\n",
      " [ 0.03788127  0.02987693]\n",
      " [ 0.03944892  0.02856662]\n",
      " [ 0.043731    0.02961764]\n",
      " [ 0.03486185  0.02521152]\n",
      " [ 0.03993758  0.02788956]\n",
      " [ 0.03850661  0.02004981]\n",
      " [ 0.04259034  0.02977017]\n",
      " [ 0.0350392   0.02886074]\n",
      " [ 0.03358242  0.02573848]\n",
      " [ 0.03184695  0.02800337]\n",
      " [ 0.02812035  0.03220433]\n",
      " [ 0.03839877  0.03261787]\n",
      " [ 0.04816382  0.03070014]\n",
      " [ 0.03891396  0.02527284]\n",
      " [ 0.03879469  0.02497408]\n",
      " [ 0.04296245  0.03170218]\n",
      " [ 0.04661978  0.03493511]\n",
      " [ 0.02502712  0.03198127]\n",
      " [ 0.04506777  0.02487571]\n",
      " [ 0.04631852  0.03001864]\n",
      " [ 0.03839557  0.02890256]\n",
      " [ 0.040872    0.02583664]\n",
      " [ 0.04259415  0.02937092]\n",
      " [ 0.0391977   0.02869921]\n",
      " [ 0.04061632  0.02458142]\n",
      " [ 0.03734651  0.03073103]\n",
      " [ 0.03446496  0.02709956]\n",
      " [ 0.0391465   0.02635407]\n",
      " [ 0.03729321  0.03017168]\n",
      " [ 0.04061699  0.03217267]\n",
      " [ 0.03561296  0.0281028 ]\n",
      " [ 0.03798459  0.02959871]\n",
      " [ 0.04074804  0.02463056]\n",
      " [ 0.03663983  0.02629114]\n",
      " [ 0.03435913  0.02584965]\n",
      " [ 0.03259475  0.02851449]\n",
      " [ 0.03735011  0.0239228 ]\n",
      " [ 0.04295094  0.02620115]\n",
      " [ 0.03894463  0.01963262]\n",
      " [ 0.04094577  0.02909516]\n",
      " [ 0.03700855  0.03081225]\n",
      " [ 0.03812235  0.0261314 ]\n",
      " [ 0.03707128  0.0237374 ]\n",
      " [ 0.0422885   0.03068356]\n",
      " [ 0.04091071  0.02714534]\n",
      " [ 0.05087936  0.03514792]\n",
      " [ 0.04097626  0.02510985]\n",
      " [ 0.04119056  0.02533984]\n",
      " [ 0.04178641  0.02422761]\n",
      " [ 0.03620085  0.0280477 ]\n",
      " [ 0.0405019   0.029364  ]\n",
      " [ 0.02596761  0.02929578]\n",
      " [ 0.04059475  0.02465906]\n",
      " [ 0.04135306  0.0261147 ]\n",
      " [ 0.03813668  0.02654925]\n",
      " [ 0.05212634  0.02830231]\n",
      " [ 0.03842197  0.02793959]\n",
      " [ 0.03943336  0.03333631]\n",
      " [ 0.04301109  0.02627346]\n",
      " [ 0.04351662  0.02544961]\n",
      " [ 0.04579503  0.03213468]\n",
      " [ 0.03804614  0.02825848]\n",
      " [ 0.03867458  0.02611673]\n",
      " [ 0.0353256   0.02270013]\n",
      " [ 0.03950733  0.0317272 ]\n",
      " [ 0.05023003  0.03000362]\n",
      " [ 0.04904013  0.03089569]\n",
      " [ 0.0358002   0.02623741]\n",
      " [ 0.03303738  0.02903408]\n",
      " [ 0.02831103  0.02772519]\n",
      " [ 0.04693238  0.02895944]\n",
      " [ 0.03284885  0.02395658]\n",
      " [ 0.03977897  0.02993269]\n",
      " [ 0.04042656  0.02882626]\n",
      " [ 0.03658374  0.02920627]\n",
      " [ 0.04396993  0.02773361]\n",
      " [ 0.039817    0.02732451]\n",
      " [ 0.03216522  0.02647342]\n",
      " [ 0.04635199  0.02863055]\n",
      " [ 0.04922459  0.03032838]\n",
      " [ 0.03741756  0.02951292]\n",
      " [ 0.04037224  0.0278944 ]\n",
      " [ 0.04419932  0.02729627]\n",
      " [ 0.04381229  0.02877681]\n",
      " [ 0.03515196  0.0231658 ]\n",
      " [ 0.04484921  0.03032213]\n",
      " [ 0.04060955  0.03313787]\n",
      " [ 0.0410507   0.02893987]\n",
      " [ 0.04360175  0.02934304]\n",
      " [ 0.04309996  0.02850094]\n",
      " [ 0.04205369  0.03096921]\n",
      " [ 0.0389014   0.0285039 ]\n",
      " [ 0.04121877  0.03145924]\n",
      " [ 0.02493581  0.02983605]\n",
      " [ 0.04449574  0.03009095]\n",
      " [ 0.03993039  0.02966782]\n",
      " [ 0.03653501  0.03073406]\n",
      " [ 0.03756632  0.02973532]\n",
      " [ 0.04548701  0.02970855]\n",
      " [ 0.02362051  0.026665  ]\n",
      " [ 0.03801214  0.02580917]\n",
      " [ 0.04103043  0.02359351]\n",
      " [ 0.03819551  0.03438051]\n",
      " [ 0.04027449  0.03262114]\n",
      " [ 0.04174124  0.03343408]\n",
      " [ 0.04060954  0.02704381]\n",
      " [ 0.03605165  0.02677645]\n",
      " [ 0.04496225  0.03062151]\n",
      " [ 0.03381624  0.02599042]\n",
      " [ 0.03698995  0.02623623]\n",
      " [ 0.03468209  0.02459039]\n",
      " [ 0.04193128  0.0270838 ]\n",
      " [ 0.03413019  0.02821046]\n",
      " [ 0.03588489  0.02538084]\n",
      " [ 0.04175866  0.03352636]\n",
      " [ 0.03805898  0.03418493]\n",
      " [ 0.0436117   0.0275402 ]\n",
      " [ 0.0430987   0.02721835]\n",
      " [ 0.04177369  0.03130189]\n",
      " [ 0.04190588  0.02515419]\n",
      " [ 0.03396906  0.03041325]\n",
      " [ 0.04051609  0.02541905]\n",
      " [ 0.04191328  0.03319032]\n",
      " [ 0.04563049  0.02800109]\n",
      " [ 0.04036244  0.02995973]\n",
      " [ 0.04530281  0.03002274]\n",
      " [ 0.04699854  0.02868585]\n",
      " [ 0.04270979  0.0235809 ]\n",
      " [ 0.03791019  0.02895341]\n",
      " [ 0.04151479  0.02647295]\n",
      " [ 0.04550744  0.03438512]\n",
      " [ 0.04738714  0.02444049]\n",
      " [ 0.03509785  0.02676985]\n",
      " [ 0.04334182  0.03039776]\n",
      " [ 0.04478874  0.0294831 ]\n",
      " [ 0.03771633  0.02734267]\n",
      " [ 0.03686384  0.03020614]\n",
      " [ 0.04023016  0.02965486]\n",
      " [ 0.04626925  0.02939485]\n",
      " [ 0.03769919  0.03127353]\n",
      " [ 0.04371295  0.02651341]\n",
      " [ 0.04285638  0.02953972]\n",
      " [ 0.03684703  0.02769416]\n",
      " [ 0.04743299  0.02984978]\n",
      " [ 0.04032477  0.02966306]\n",
      " [ 0.03816203  0.02791199]\n",
      " [ 0.03677148  0.02380861]\n",
      " [ 0.03183555  0.02816116]\n",
      " [ 0.04382364  0.03214792]\n",
      " [ 0.03761201  0.02841667]\n",
      " [ 0.03890917  0.02210011]\n",
      " [ 0.03729435  0.02804552]\n",
      " [ 0.03653317  0.02611366]\n",
      " [ 0.04773149  0.02716446]\n",
      " [ 0.03477502  0.02305935]\n",
      " [ 0.04118916  0.02999876]\n",
      " [ 0.04116262  0.02813607]\n",
      " [ 0.03791247  0.02428741]\n",
      " [ 0.04828296  0.0381752 ]\n",
      " [ 0.0424305   0.02663008]\n",
      " [ 0.03622169  0.02971792]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create Optuna study\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "\n",
    "optimal_alpha = study.best_params['alpha']\n",
    "optimal_epsilon_decay = study.best_params['epsilon_decay']\n",
    "optimal_alpha_decay = study.best_params['alpha_decay']\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    environment = environment\n",
    "    num_of_episodes = 15000\n",
    "    alpha = optimal_alpha\n",
    "    #gamma = 0\n",
    "    epsilon_decay = optimal_epsilon_decay\n",
    "    alpha_decay = optimal_alpha_decay\n",
    "    finding_parameters =  False\n",
    "    Q_tubular,_,_,_,_, = implement_Q_learning(environment, num_of_episodes, alpha, gamma, epsilon_decay, alpha_decay, finding_parameters)\n",
    "    print(f\"\\n {i} FINAL OPTIMAL POLICY {np.argmax(Q_tubular,axis=1)}\")\n",
    "\n",
    "num_of_episodes = 20000\n",
    "Q_tubular,_, mean_rewards, epsilon_tracker, alpha_tracker = implement_Q_learning(environment, num_of_episodes=num_of_episodes, alpha=0.5, gamma=gamma)\n",
    "print(np.argmax(Q_opt,axis=1))\n",
    "print(f\"\\nTabular Q-Learnig Policy {np.argmax(Q_tubular,axis=1)}\")\n",
    "print(\"\\nQopt = \\n\",Q_opt)\n",
    "print(\"Qtabular = \\n\",Q_tubular)\n",
    "\n",
    "\n",
    "plot_mean_rewards = []\n",
    "samples = 20\n",
    "for i in range(samples):\n",
    "    cut = int(num_of_episodes / samples)\n",
    "    start = cut * i\n",
    "    end = cut * (i + 1)\n",
    "    mean_reward = np.mean(mean_rewards[start:end])\n",
    "    plot_mean_rewards.append(mean_reward)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, samples+1), plot_mean_rewards, marker='x')\n",
    "plt.xlabel(f'Number Of Epochs x {cut} ')\n",
    "plt.ylabel('Mean Episode Reward')\n",
    "plt.title('Mean Rewards')\n",
    "plt.xticks(range(1, samples+1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Learning Rate (alpha) and Epsilon')\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.grid(True)\n",
    "plt.plot(np.arange(0, num_of_episodes+1), epsilon_tracker, label='Exploration Rate Over Time')\n",
    "plt.plot(np.arange(0, num_of_episodes+1), alpha_tracker, label='Learning Rate (alpha) Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# diff = count_tables_differences(Q_opt,Q_tubular)\n",
    "# print(\"DIfference: \",diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Run the DQN for the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3805/6000 [06:22<03:40,  9.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[441], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m NN_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m      3\u001b[0m dql \u001b[38;5;241m=\u001b[39m stock_market_trading_DQN()\n\u001b[1;32m----> 4\u001b[0m optimal_network,mean_reward \u001b[38;5;241m=\u001b[39m \u001b[43mdql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_DQN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_of_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNN_learning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m dql\u001b[38;5;241m.\u001b[39mtest_DQN(\u001b[38;5;241m10\u001b[39m,environment)  \n\u001b[0;32m      8\u001b[0m plot_mean_rewards \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[433], line 136\u001b[0m, in \u001b[0;36mstock_market_trading_DQN.train_DQN\u001b[1;34m(self, episodes, environment, gamma, lr)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(memory_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_batch_size):\n\u001b[0;32m    133\u001b[0m \n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m#mini_batch = self.sample_mem_buffer(memory_buffer, self.min_batch_size)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     mini_batch \u001b[38;5;241m=\u001b[39m memory_buffer\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_batch_size)\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dqn\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Decay epsilon\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(epsilon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mepisodes, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[433], line 190\u001b[0m, in \u001b[0;36mstock_market_trading_DQN.optimize\u001b[1;34m(self, mini_batch, policy_dqn, target_dqn)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Optimize the model by running back-propagation\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 190\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\vagga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vagga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vagga\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_of_episodes = 6000\n",
    "NN_learning_rate = 0.01\n",
    "dql = stock_market_trading_DQN()\n",
    "optimal_network,mean_reward = dql.train_DQN(num_of_episodes,environment,gamma,NN_learning_rate)\n",
    "dql.test_DQN(10,environment)  \n",
    "\n",
    "\n",
    "plot_mean_rewards = []\n",
    "samples = 20\n",
    "for i in range(samples):\n",
    "    cut = int(num_of_episodes / samples)\n",
    "    start = cut * i\n",
    "    end = cut * (i + 1)\n",
    "    mean_rewards = np.mean(mean_reward[start:end])\n",
    "    plot_mean_rewards.append(mean_rewards)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, samples+1), plot_mean_rewards, marker='x')\n",
    "plt.xlabel(f'Number Of Epochs x {cut} ')\n",
    "plt.ylabel('Mean Episode Reward')\n",
    "plt.title('Mean Rewards')\n",
    "plt.xticks(range(1, samples+1))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Optimal Policies Generated from diffrent algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 Optimal Policy\n",
      "State 0: Action 0\n",
      "State 1: Action 0\n",
      "State 2: Action 0\n",
      "State 3: Action 0\n",
      "State 4: Action 1\n",
      "State 5: Action 1\n",
      "State 6: Action 0\n",
      "State 7: Action 0\n",
      "State 8: Action 1\n",
      "State 9: Action 1\n",
      "State 10: Action 0\n",
      "State 11: Action 0\n",
      "State 12: Action 0\n",
      "State 13: Action 0\n",
      "State 14: Action 0\n",
      "State 15: Action 1\n",
      "State 16: Action 0\n",
      "State 17: Action 0\n",
      "State 18: Action 0\n",
      "State 19: Action 0\n",
      "State 20: Action 0\n",
      "State 21: Action 0\n",
      "State 22: Action 0\n",
      "State 23: Action 0\n",
      "State 24: Action 0\n",
      "State 25: Action 1\n",
      "State 26: Action 0\n",
      "State 27: Action 1\n",
      "State 28: Action 0\n",
      "State 29: Action 0\n",
      "State 30: Action 1\n",
      "State 31: Action 0\n",
      "State 32: Action 0\n",
      "State 33: Action 0\n",
      "State 34: Action 1\n",
      "State 35: Action 0\n",
      "State 36: Action 0\n",
      "State 37: Action 0\n",
      "State 38: Action 0\n",
      "State 39: Action 0\n",
      "State 40: Action 1\n",
      "State 41: Action 1\n",
      "State 42: Action 1\n",
      "State 43: Action 0\n",
      "State 44: Action 0\n",
      "State 45: Action 1\n",
      "State 46: Action 0\n",
      "State 47: Action 0\n",
      "State 48: Action 0\n",
      "State 49: Action 0\n",
      "State 50: Action 0\n",
      "State 51: Action 1\n",
      "State 52: Action 0\n",
      "State 53: Action 1\n",
      "State 54: Action 0\n",
      "State 55: Action 1\n",
      "State 56: Action 1\n",
      "State 57: Action 0\n",
      "State 58: Action 0\n",
      "State 59: Action 1\n",
      "State 60: Action 1\n",
      "State 61: Action 1\n",
      "State 62: Action 0\n",
      "State 63: Action 0\n",
      "State 64: Action 0\n",
      "State 65: Action 0\n",
      "State 66: Action 1\n",
      "State 67: Action 0\n",
      "State 68: Action 1\n",
      "State 69: Action 1\n",
      "State 70: Action 0\n",
      "State 71: Action 0\n",
      "State 72: Action 1\n",
      "State 73: Action 0\n",
      "State 74: Action 0\n",
      "State 75: Action 0\n",
      "State 76: Action 1\n",
      "State 77: Action 1\n",
      "State 78: Action 1\n",
      "State 79: Action 0\n",
      "State 80: Action 0\n",
      "State 81: Action 1\n",
      "State 82: Action 0\n",
      "State 83: Action 0\n",
      "State 84: Action 0\n",
      "State 85: Action 0\n",
      "State 86: Action 0\n",
      "State 87: Action 1\n",
      "State 88: Action 0\n",
      "State 89: Action 0\n",
      "State 90: Action 0\n",
      "State 91: Action 0\n",
      "State 92: Action 1\n",
      "State 93: Action 0\n",
      "State 94: Action 1\n",
      "State 95: Action 1\n",
      "State 96: Action 0\n",
      "State 97: Action 0\n",
      "State 98: Action 1\n",
      "State 99: Action 1\n",
      "State 100: Action 1\n",
      "State 101: Action 0\n",
      "State 102: Action 0\n",
      "State 103: Action 1\n",
      "State 104: Action 0\n",
      "State 105: Action 0\n",
      "State 106: Action 0\n",
      "State 107: Action 1\n",
      "State 108: Action 1\n",
      "State 109: Action 1\n",
      "State 110: Action 0\n",
      "State 111: Action 0\n",
      "State 112: Action 0\n",
      "State 113: Action 1\n",
      "State 114: Action 0\n",
      "State 115: Action 1\n",
      "State 116: Action 0\n",
      "State 117: Action 0\n",
      "State 118: Action 0\n",
      "State 119: Action 0\n",
      "State 120: Action 0\n",
      "State 121: Action 0\n",
      "State 122: Action 0\n",
      "State 123: Action 0\n",
      "State 124: Action 0\n",
      "State 125: Action 0\n",
      "State 126: Action 1\n",
      "State 127: Action 1\n",
      "State 128: Action 0\n",
      "State 129: Action 0\n",
      "State 130: Action 0\n",
      "State 131: Action 0\n",
      "State 132: Action 0\n",
      "State 133: Action 0\n",
      "State 134: Action 1\n",
      "State 135: Action 1\n",
      "State 136: Action 1\n",
      "State 137: Action 0\n",
      "State 138: Action 1\n",
      "State 139: Action 1\n",
      "State 140: Action 0\n",
      "State 141: Action 0\n",
      "State 142: Action 1\n",
      "State 143: Action 0\n",
      "State 144: Action 1\n",
      "State 145: Action 0\n",
      "State 146: Action 1\n",
      "State 147: Action 0\n",
      "State 148: Action 1\n",
      "State 149: Action 0\n",
      "State 150: Action 0\n",
      "State 151: Action 1\n",
      "State 152: Action 0\n",
      "State 153: Action 0\n",
      "State 154: Action 1\n",
      "State 155: Action 0\n",
      "State 156: Action 1\n",
      "State 157: Action 0\n",
      "State 158: Action 0\n",
      "State 159: Action 0\n",
      "State 160: Action 1\n",
      "State 161: Action 1\n",
      "State 162: Action 1\n",
      "State 163: Action 0\n",
      "State 164: Action 0\n",
      "State 165: Action 0\n",
      "State 166: Action 0\n",
      "State 167: Action 1\n",
      "State 168: Action 0\n",
      "State 169: Action 0\n",
      "State 170: Action 1\n",
      "State 171: Action 1\n",
      "State 172: Action 0\n",
      "State 173: Action 0\n",
      "State 174: Action 1\n",
      "State 175: Action 0\n",
      "State 176: Action 0\n",
      "State 177: Action 1\n",
      "State 178: Action 1\n",
      "State 179: Action 1\n",
      "State 180: Action 0\n",
      "State 181: Action 0\n",
      "State 182: Action 0\n",
      "State 183: Action 1\n",
      "State 184: Action 1\n",
      "State 185: Action 0\n",
      "State 186: Action 0\n",
      "State 187: Action 1\n",
      "State 188: Action 1\n",
      "State 189: Action 1\n",
      "State 190: Action 1\n",
      "State 191: Action 0\n",
      "State 192: Action 0\n",
      "State 193: Action 0\n",
      "State 194: Action 0\n",
      "State 195: Action 0\n",
      "State 196: Action 0\n",
      "State 197: Action 0\n",
      "State 198: Action 0\n",
      "State 199: Action 0\n",
      "State 200: Action 0\n",
      "State 201: Action 0\n",
      "State 202: Action 0\n",
      "State 203: Action 0\n",
      "State 204: Action 1\n",
      "State 205: Action 0\n",
      "State 206: Action 0\n",
      "State 207: Action 0\n",
      "State 208: Action 0\n",
      "State 209: Action 0\n",
      "State 210: Action 0\n",
      "State 211: Action 0\n",
      "State 212: Action 0\n",
      "State 213: Action 0\n",
      "State 214: Action 0\n",
      "State 215: Action 0\n",
      "State 216: Action 0\n",
      "State 217: Action 0\n",
      "State 218: Action 0\n",
      "State 219: Action 0\n",
      "State 220: Action 0\n",
      "State 221: Action 0\n",
      "State 222: Action 0\n",
      "State 223: Action 0\n",
      "State 224: Action 0\n",
      "State 225: Action 0\n",
      "State 226: Action 0\n",
      "State 227: Action 0\n",
      "State 228: Action 0\n",
      "State 229: Action 0\n",
      "State 230: Action 0\n",
      "State 231: Action 0\n",
      "State 232: Action 0\n",
      "State 233: Action 1\n",
      "State 234: Action 0\n",
      "State 235: Action 0\n",
      "State 236: Action 0\n",
      "State 237: Action 0\n",
      "State 238: Action 0\n",
      "State 239: Action 0\n",
      "State 240: Action 1\n",
      "State 241: Action 0\n",
      "State 242: Action 0\n",
      "State 243: Action 0\n",
      "State 244: Action 0\n",
      "State 245: Action 0\n",
      "State 246: Action 0\n",
      "State 247: Action 0\n",
      "State 248: Action 0\n",
      "State 249: Action 0\n",
      "State 250: Action 0\n",
      "State 251: Action 0\n",
      "State 252: Action 0\n",
      "State 253: Action 0\n",
      "State 254: Action 0\n",
      "State 255: Action 0\n",
      "State 256: Action 0\n",
      "State 257: Action 0\n",
      "State 258: Action 0\n",
      "State 259: Action 0\n",
      "State 260: Action 0\n",
      "State 261: Action 0\n",
      "State 262: Action 0\n",
      "State 263: Action 0\n",
      "State 264: Action 0\n",
      "State 265: Action 0\n",
      "State 266: Action 0\n",
      "State 267: Action 0\n",
      "State 268: Action 0\n",
      "State 269: Action 0\n",
      "State 270: Action 0\n",
      "State 271: Action 0\n",
      "State 272: Action 0\n",
      "State 273: Action 0\n",
      "State 274: Action 0\n",
      "State 275: Action 0\n",
      "State 276: Action 0\n",
      "State 277: Action 0\n",
      "State 278: Action 0\n",
      "State 279: Action 0\n",
      "State 280: Action 0\n",
      "State 281: Action 0\n",
      "State 282: Action 0\n",
      "State 283: Action 0\n",
      "State 284: Action 0\n",
      "State 285: Action 0\n",
      "State 286: Action 0\n",
      "State 287: Action 0\n",
      "State 288: Action 0\n",
      "State 289: Action 0\n",
      "State 290: Action 0\n",
      "State 291: Action 1\n",
      "State 292: Action 1\n",
      "State 293: Action 0\n",
      "State 294: Action 0\n",
      "State 295: Action 0\n",
      "State 296: Action 0\n",
      "State 297: Action 0\n",
      "State 298: Action 0\n",
      "State 299: Action 0\n",
      "State 300: Action 0\n",
      "State 301: Action 0\n",
      "State 302: Action 0\n",
      "State 303: Action 0\n",
      "State 304: Action 0\n",
      "State 305: Action 0\n",
      "State 306: Action 0\n",
      "State 307: Action 0\n",
      "State 308: Action 0\n",
      "State 309: Action 0\n",
      "State 310: Action 0\n",
      "State 311: Action 0\n",
      "State 312: Action 0\n",
      "State 313: Action 0\n",
      "State 314: Action 0\n",
      "State 315: Action 0\n",
      "State 316: Action 0\n",
      "State 317: Action 0\n",
      "State 318: Action 0\n",
      "State 319: Action 0\n",
      "State 320: Action 0\n",
      "State 321: Action 0\n",
      "State 322: Action 0\n",
      "State 323: Action 0\n",
      "State 324: Action 0\n",
      "State 325: Action 0\n",
      "State 326: Action 0\n",
      "State 327: Action 0\n",
      "State 328: Action 0\n",
      "State 329: Action 0\n",
      "State 330: Action 0\n",
      "State 331: Action 0\n",
      "State 332: Action 0\n",
      "State 333: Action 0\n",
      "State 334: Action 0\n",
      "State 335: Action 0\n",
      "State 336: Action 0\n",
      "State 337: Action 0\n",
      "State 338: Action 0\n",
      "State 339: Action 0\n",
      "State 340: Action 0\n",
      "State 341: Action 0\n",
      "State 342: Action 0\n",
      "State 343: Action 0\n",
      "State 344: Action 0\n",
      "State 345: Action 0\n",
      "State 346: Action 0\n",
      "State 347: Action 0\n",
      "State 348: Action 0\n",
      "State 349: Action 0\n",
      "State 350: Action 0\n",
      "State 351: Action 0\n",
      "State 352: Action 0\n",
      "State 353: Action 0\n",
      "State 354: Action 0\n",
      "State 355: Action 0\n",
      "State 356: Action 0\n",
      "State 357: Action 0\n",
      "State 358: Action 0\n",
      "State 359: Action 0\n",
      "State 360: Action 0\n",
      "State 361: Action 0\n",
      "State 362: Action 0\n",
      "State 363: Action 0\n",
      "State 364: Action 0\n",
      "State 365: Action 0\n",
      "State 366: Action 0\n",
      "State 367: Action 0\n",
      "State 368: Action 0\n",
      "State 369: Action 0\n",
      "State 370: Action 0\n",
      "State 371: Action 0\n",
      "State 372: Action 0\n",
      "State 373: Action 0\n",
      "State 374: Action 0\n",
      "State 375: Action 0\n",
      "State 376: Action 0\n",
      "State 377: Action 0\n",
      "State 378: Action 0\n",
      "State 379: Action 0\n",
      "State 380: Action 0\n",
      "State 381: Action 0\n",
      "State 382: Action 0\n",
      "State 383: Action 0\n",
      "\n",
      "Optimal Q =  [[0.05628898 0.03925502]\n",
      " [0.0693186  0.02143849]\n",
      " [0.05944512 0.0366098 ]\n",
      " [0.05559298 0.04067889]\n",
      " [0.02062907 0.02745481]\n",
      " [0.01313807 0.0173452 ]\n",
      " [0.04911497 0.03718754]\n",
      " [0.06293295 0.01443758]\n",
      " [0.01119837 0.04096399]\n",
      " [0.01882785 0.03256808]\n",
      " [0.03404288 0.02027562]\n",
      " [0.06815747 0.03204   ]\n",
      " [0.04471635 0.02707122]\n",
      " [0.03459056 0.03190136]\n",
      " [0.06266718 0.02461965]\n",
      " [0.03287897 0.04066295]\n",
      " [0.06313888 0.02629414]\n",
      " [0.01939002 0.01419895]\n",
      " [0.03047787 0.02454402]\n",
      " [0.06915962 0.03705491]\n",
      " [0.0602981  0.02972048]\n",
      " [0.04874877 0.02858591]\n",
      " [0.03626344 0.03027669]\n",
      " [0.0479759  0.02053713]\n",
      " [0.05964311 0.01929412]\n",
      " [0.01956896 0.0311405 ]\n",
      " [0.06716298 0.02045444]\n",
      " [0.03199113 0.03589264]\n",
      " [0.04953439 0.0260072 ]\n",
      " [0.05635209 0.01960172]\n",
      " [0.01678246 0.02712133]\n",
      " [0.05458062 0.03794334]\n",
      " [0.04882917 0.03247659]\n",
      " [0.0632186  0.03173599]\n",
      " [0.02679715 0.02957703]\n",
      " [0.02310747 0.02045861]\n",
      " [0.04914501 0.02578823]\n",
      " [0.0599856  0.03537464]\n",
      " [0.06956715 0.02599338]\n",
      " [0.03957216 0.0175107 ]\n",
      " [0.02885094 0.04508294]\n",
      " [0.01960695 0.04231756]\n",
      " [0.0168301  0.01998255]\n",
      " [0.07106203 0.02857687]\n",
      " [0.05443114 0.02879264]\n",
      " [0.01615184 0.02724047]\n",
      " [0.04003722 0.03966462]\n",
      " [0.03720954 0.02398281]\n",
      " [0.04688983 0.0382763 ]\n",
      " [0.01819408 0.01658705]\n",
      " [0.06657012 0.03877382]\n",
      " [0.02406601 0.04197088]\n",
      " [0.0669213  0.03768009]\n",
      " [0.01349662 0.01747735]\n",
      " [0.06016081 0.01977817]\n",
      " [0.01471907 0.02302561]\n",
      " [0.03935115 0.0419479 ]\n",
      " [0.0325496  0.02097284]\n",
      " [0.05124468 0.02370002]\n",
      " [0.02113802 0.03044372]\n",
      " [0.01444332 0.03314761]\n",
      " [0.03047054 0.03223943]\n",
      " [0.01787849 0.01666457]\n",
      " [0.04339601 0.02515161]\n",
      " [0.05646769 0.03036841]\n",
      " [0.05132525 0.02704565]\n",
      " [0.03385949 0.03507724]\n",
      " [0.04478875 0.02457067]\n",
      " [0.01564301 0.02479331]\n",
      " [0.03215318 0.03461297]\n",
      " [0.02679547 0.02615618]\n",
      " [0.0353736  0.03496992]\n",
      " [0.01707561 0.02375555]\n",
      " [0.05966778 0.03933531]\n",
      " [0.05447361 0.02508825]\n",
      " [0.07097327 0.038446  ]\n",
      " [0.03039615 0.03042567]\n",
      " [0.04326171 0.05164529]\n",
      " [0.01238151 0.03481767]\n",
      " [0.06642554 0.02597568]\n",
      " [0.03932272 0.03364121]\n",
      " [0.0023885  0.04523113]\n",
      " [0.04379464 0.03343289]\n",
      " [0.06450339 0.01072937]\n",
      " [0.05292698 0.03629028]\n",
      " [0.06531874 0.02876777]\n",
      " [0.05895465 0.03290663]\n",
      " [0.01853709 0.02618402]\n",
      " [0.06190284 0.03532445]\n",
      " [0.05601836 0.03236077]\n",
      " [0.0251868  0.01773555]\n",
      " [0.04649866 0.02323567]\n",
      " [0.01224441 0.02639059]\n",
      " [0.04404799 0.02653406]\n",
      " [0.00806386 0.02225015]\n",
      " [0.02765396 0.04254355]\n",
      " [0.049747   0.02212412]\n",
      " [0.03903799 0.02992606]\n",
      " [0.02243516 0.03294377]\n",
      " [0.05042717 0.05168164]\n",
      " [0.01508947 0.04557485]\n",
      " [0.0387766  0.02125382]\n",
      " [0.0415467  0.03343031]\n",
      " [0.0077974  0.03590045]\n",
      " [0.04191042 0.02851485]\n",
      " [0.04138166 0.0384451 ]\n",
      " [0.04274488 0.01855102]\n",
      " [0.00305586 0.01709827]\n",
      " [0.01212098 0.02609686]\n",
      " [0.04257716 0.04652856]\n",
      " [0.03002605 0.01974015]\n",
      " [0.06937247 0.03156428]\n",
      " [0.07295162 0.0296445 ]\n",
      " [0.02736069 0.0353479 ]\n",
      " [0.0532058  0.02260095]\n",
      " [0.01894249 0.02239113]\n",
      " [0.04693578 0.0459355 ]\n",
      " [0.056152   0.02188779]\n",
      " [0.05081212 0.03082705]\n",
      " [0.05304334 0.02254663]\n",
      " [0.06090702 0.04582278]\n",
      " [0.03522132 0.02711181]\n",
      " [0.02544307 0.02431928]\n",
      " [0.07243834 0.03078131]\n",
      " [0.04640046 0.0243044 ]\n",
      " [0.04529637 0.03409635]\n",
      " [0.0410171  0.04307524]\n",
      " [0.03991179 0.04186448]\n",
      " [0.07454309 0.03605666]\n",
      " [0.04217039 0.02756642]\n",
      " [0.07136853 0.0301345 ]\n",
      " [0.06383378 0.03162894]\n",
      " [0.04093168 0.03278092]\n",
      " [0.07396226 0.02343157]\n",
      " [0.03926411 0.04060089]\n",
      " [0.01355052 0.03535387]\n",
      " [0.01137376 0.03654481]\n",
      " [0.04877151 0.03195076]\n",
      " [0.02627676 0.03430433]\n",
      " [0.0049262  0.03685863]\n",
      " [0.05944149 0.04187271]\n",
      " [0.03854778 0.02689162]\n",
      " [0.01429534 0.04036118]\n",
      " [0.05816945 0.02684366]\n",
      " [0.03296824 0.04521195]\n",
      " [0.06149065 0.03501259]\n",
      " [0.02794126 0.02858321]\n",
      " [0.06281041 0.01194506]\n",
      " [0.00220232 0.03123269]\n",
      " [0.05577095 0.03237885]\n",
      " [0.07180392 0.0252878 ]\n",
      " [0.01681684 0.02511708]\n",
      " [0.0427637  0.01299452]\n",
      " [0.06061325 0.02161082]\n",
      " [0.02135204 0.04176839]\n",
      " [0.05523908 0.0230493 ]\n",
      " [0.01320706 0.03390285]\n",
      " [0.03454636 0.01809011]\n",
      " [0.04705573 0.04266009]\n",
      " [0.07029535 0.02270874]\n",
      " [0.01459762 0.03203919]\n",
      " [0.01925308 0.02065675]\n",
      " [0.02765268 0.03426021]\n",
      " [0.05760238 0.03524966]\n",
      " [0.0242479  0.0140428 ]\n",
      " [0.06270967 0.02018775]\n",
      " [0.06253321 0.01484687]\n",
      " [0.02352115 0.03100177]\n",
      " [0.06087081 0.02896048]\n",
      " [0.0408642  0.03789358]\n",
      " [0.01788368 0.03118372]\n",
      " [0.03329057 0.0427016 ]\n",
      " [0.06182698 0.02409436]\n",
      " [0.03545905 0.02870234]\n",
      " [0.01609023 0.02279756]\n",
      " [0.06255661 0.02066645]\n",
      " [0.07179577 0.02660215]\n",
      " [0.02382419 0.02505026]\n",
      " [0.00959429 0.04375469]\n",
      " [0.01791515 0.02679169]\n",
      " [0.04107182 0.00967629]\n",
      " [0.0253119  0.01669282]\n",
      " [0.03674995 0.02143284]\n",
      " [0.01634338 0.03227819]\n",
      " [0.0332981  0.03531105]\n",
      " [0.05400114 0.030707  ]\n",
      " [0.04517897 0.03188288]\n",
      " [0.01745427 0.02081877]\n",
      " [0.01150877 0.02501193]\n",
      " [0.00961399 0.02870692]\n",
      " [0.01505472 0.02622352]\n",
      " [0.04507435 0.03965002]\n",
      " [0.04535477 0.03322145]\n",
      " [0.04038564 0.03001984]\n",
      " [0.03423187 0.02764332]\n",
      " [0.0329985  0.02967188]\n",
      " [0.03829048 0.0309621 ]\n",
      " [0.04122113 0.02671222]\n",
      " [0.0400342  0.02932967]\n",
      " [0.04077953 0.03209938]\n",
      " [0.04077433 0.0266257 ]\n",
      " [0.03916296 0.03048122]\n",
      " [0.03907476 0.03079695]\n",
      " [0.04076635 0.03104801]\n",
      " [0.032314   0.03406477]\n",
      " [0.04021749 0.03374742]\n",
      " [0.03817017 0.02971273]\n",
      " [0.04215228 0.02823381]\n",
      " [0.04344357 0.03000624]\n",
      " [0.03924636 0.03398759]\n",
      " [0.04062614 0.03126701]\n",
      " [0.03910206 0.03083917]\n",
      " [0.04190668 0.03077056]\n",
      " [0.03310913 0.02986801]\n",
      " [0.04461712 0.03419729]\n",
      " [0.0471824  0.02976819]\n",
      " [0.03732666 0.0317979 ]\n",
      " [0.04361947 0.03246416]\n",
      " [0.04172832 0.02737474]\n",
      " [0.0400859  0.03027118]\n",
      " [0.04626551 0.03131294]\n",
      " [0.03498218 0.02975468]\n",
      " [0.03866652 0.0313119 ]\n",
      " [0.03812533 0.03194771]\n",
      " [0.03831982 0.02896597]\n",
      " [0.04386705 0.03111615]\n",
      " [0.03604981 0.02939621]\n",
      " [0.04054857 0.0312693 ]\n",
      " [0.03853556 0.02764586]\n",
      " [0.0443635  0.02967642]\n",
      " [0.03551078 0.03279314]\n",
      " [0.03496592 0.03187692]\n",
      " [0.03367265 0.03265419]\n",
      " [0.03013647 0.03184198]\n",
      " [0.0383227  0.03129804]\n",
      " [0.04906878 0.03013061]\n",
      " [0.03897435 0.03289434]\n",
      " [0.03912957 0.03032685]\n",
      " [0.042953   0.03266795]\n",
      " [0.04654005 0.02999685]\n",
      " [0.03006302 0.03112129]\n",
      " [0.04458377 0.02808297]\n",
      " [0.0466945  0.03138912]\n",
      " [0.03751665 0.02851475]\n",
      " [0.04090609 0.02931369]\n",
      " [0.04284902 0.02976807]\n",
      " [0.03983925 0.03101376]\n",
      " [0.03968735 0.02935455]\n",
      " [0.03777385 0.03093347]\n",
      " [0.03414045 0.02966247]\n",
      " [0.03993086 0.02720932]\n",
      " [0.03820941 0.03294672]\n",
      " [0.03998564 0.03330223]\n",
      " [0.03575789 0.03133084]\n",
      " [0.03877498 0.03240591]\n",
      " [0.04108835 0.02820297]\n",
      " [0.0376964  0.02843486]\n",
      " [0.03500034 0.03104324]\n",
      " [0.03440942 0.02928361]\n",
      " [0.0385972  0.02776686]\n",
      " [0.04257187 0.02808172]\n",
      " [0.03939616 0.02569452]\n",
      " [0.04122097 0.02772565]\n",
      " [0.03674128 0.02804126]\n",
      " [0.0374741  0.0269905 ]\n",
      " [0.03732753 0.0309948 ]\n",
      " [0.04292614 0.0313044 ]\n",
      " [0.04229636 0.03201725]\n",
      " [0.05028914 0.03265779]\n",
      " [0.04091364 0.02950899]\n",
      " [0.04162336 0.02848995]\n",
      " [0.04233808 0.02808383]\n",
      " [0.03645554 0.02851842]\n",
      " [0.03960996 0.02925766]\n",
      " [0.03186141 0.02997195]\n",
      " [0.04088471 0.02935218]\n",
      " [0.04096006 0.02761599]\n",
      " [0.03922031 0.02885178]\n",
      " [0.05150006 0.03024924]\n",
      " [0.03899449 0.02783315]\n",
      " [0.03868848 0.03201891]\n",
      " [0.04280147 0.03049298]\n",
      " [0.0442649  0.02881966]\n",
      " [0.04554848 0.03010338]\n",
      " [0.03762241 0.03128172]\n",
      " [0.03736562 0.02901956]\n",
      " [0.03513846 0.02584246]\n",
      " [0.03888463 0.02972596]\n",
      " [0.04984365 0.03160214]\n",
      " [0.04885519 0.03044685]\n",
      " [0.03648448 0.02874432]\n",
      " [0.03261171 0.0341326 ]\n",
      " [0.02932865 0.03124785]\n",
      " [0.04776024 0.02963076]\n",
      " [0.03274135 0.02896978]\n",
      " [0.03966075 0.02796513]\n",
      " [0.03933483 0.03164081]\n",
      " [0.03694767 0.03058857]\n",
      " [0.04407362 0.03027846]\n",
      " [0.04020676 0.02666901]\n",
      " [0.03123093 0.0284934 ]\n",
      " [0.04510905 0.02988576]\n",
      " [0.0479038  0.02846169]\n",
      " [0.03911188 0.03229576]\n",
      " [0.04008476 0.03235843]\n",
      " [0.04353979 0.02730584]\n",
      " [0.04440609 0.02941112]\n",
      " [0.03494435 0.02864352]\n",
      " [0.04433427 0.03009935]\n",
      " [0.04216801 0.03317731]\n",
      " [0.04095499 0.02942865]\n",
      " [0.04393509 0.02965503]\n",
      " [0.043783   0.03003064]\n",
      " [0.04100226 0.02744571]\n",
      " [0.04057664 0.03139409]\n",
      " [0.04049697 0.03118521]\n",
      " [0.02897706 0.02866315]\n",
      " [0.04389861 0.03078704]\n",
      " [0.03973792 0.02857531]\n",
      " [0.03798922 0.02997779]\n",
      " [0.03707011 0.02966052]\n",
      " [0.04569541 0.03240042]\n",
      " [0.02960205 0.02668612]\n",
      " [0.038134   0.02906955]\n",
      " [0.04052142 0.03015897]\n",
      " [0.03884349 0.03388434]\n",
      " [0.04000444 0.03005146]\n",
      " [0.04177308 0.03380974]\n",
      " [0.04082341 0.02622392]\n",
      " [0.03607128 0.02688945]\n",
      " [0.04494751 0.03041079]\n",
      " [0.03314469 0.02906239]\n",
      " [0.03801803 0.03109188]\n",
      " [0.0351439  0.02920351]\n",
      " [0.04009346 0.02888753]\n",
      " [0.03529197 0.03015958]\n",
      " [0.03645118 0.02875079]\n",
      " [0.04176218 0.03127567]\n",
      " [0.03834674 0.0339465 ]\n",
      " [0.04343452 0.02834418]\n",
      " [0.0433112  0.02770081]\n",
      " [0.04174456 0.03222616]\n",
      " [0.04153503 0.02742603]\n",
      " [0.03527024 0.03065045]\n",
      " [0.03965749 0.02903284]\n",
      " [0.04317261 0.03442968]\n",
      " [0.04569379 0.02866141]\n",
      " [0.04133673 0.03166999]\n",
      " [0.04634378 0.03478606]\n",
      " [0.04806239 0.0313957 ]\n",
      " [0.0421055  0.02677786]\n",
      " [0.03758405 0.02931119]\n",
      " [0.04155053 0.0262759 ]\n",
      " [0.04572957 0.03305467]\n",
      " [0.04645366 0.0252645 ]\n",
      " [0.0347728  0.02706117]\n",
      " [0.04334679 0.03112589]\n",
      " [0.04306563 0.03079677]\n",
      " [0.03761215 0.02978906]\n",
      " [0.03496931 0.03069176]\n",
      " [0.03884107 0.02994046]\n",
      " [0.04574549 0.02745179]\n",
      " [0.03833    0.03184456]\n",
      " [0.04324997 0.02833507]\n",
      " [0.04350973 0.02825205]\n",
      " [0.036645   0.02999247]\n",
      " [0.04676741 0.02703993]\n",
      " [0.04032746 0.02931339]\n",
      " [0.03788094 0.02790522]\n",
      " [0.03854234 0.02765638]\n",
      " [0.03207183 0.03052326]\n",
      " [0.04358235 0.03110876]\n",
      " [0.03674691 0.03120761]\n",
      " [0.03987754 0.02817284]\n",
      " [0.03670441 0.02912967]\n",
      " [0.03816091 0.02744917]\n",
      " [0.04612051 0.0296269 ]\n",
      " [0.03600834 0.02521   ]\n",
      " [0.04174627 0.03194349]\n",
      " [0.04185401 0.03101021]\n",
      " [0.03762235 0.02993898]\n",
      " [0.04804686 0.03470395]\n",
      " [0.04265531 0.03433936]\n",
      " [0.03771365 0.03060361]]\n",
      "================================================================\n",
      "Phase 2 - Tubular Q-Learning Optimal Policy\n",
      "[0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 0\n",
      " 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "================================================================\n",
      "Phase 2 - DQN Optimal Policy\n",
      "00,0,[+0.04 +0.03]\n",
      "01,0,[+0.06 +0.01]\n",
      "02,0,[+0.04 +0.03]\n",
      "03,0,[+0.04 +0.03]\n",
      "\n",
      "04,0,[+0.04 +0.03]\n",
      "05,0,[+0.04 +0.03]\n",
      "06,0,[+0.04 +0.03]\n",
      "07,0,[+0.07 +0.03]\n",
      "\n",
      "08,0,[+0.04 +0.03]\n",
      "09,0,[+0.04 +0.03]\n",
      "10,0,[+0.04 +0.03]\n",
      "11,0,[+0.07 +0.00]\n",
      "\n",
      "12,0,[+0.04 +0.03]\n",
      "13,0,[+0.04 +0.03]\n",
      "14,0,[+0.06 +0.02]\n",
      "15,0,[+0.04 +0.03]\n",
      "\n",
      "16,0,[+0.05 +0.03]\n",
      "17,0,[+0.04 +0.03]\n",
      "18,0,[+0.04 +0.03]\n",
      "19,0,[+0.09 +0.01]\n",
      "\n",
      "20,0,[+0.04 +0.03]\n",
      "21,0,[+0.04 +0.03]\n",
      "22,0,[+0.04 +0.03]\n",
      "23,0,[+0.04 +0.03]\n",
      "\n",
      "24,0,[+0.06 +0.02]\n",
      "25,0,[+0.04 +0.03]\n",
      "26,0,[+0.06 +0.02]\n",
      "27,0,[+0.04 +0.03]\n",
      "\n",
      "28,0,[+0.04 +0.03]\n",
      "29,0,[+0.04 +0.03]\n",
      "30,0,[+0.04 +0.03]\n",
      "31,0,[+0.04 +0.03]\n",
      "\n",
      "32,0,[+0.04 +0.03]\n",
      "33,0,[+0.04 +0.03]\n",
      "34,0,[+0.04 +0.03]\n",
      "35,0,[+0.04 +0.03]\n",
      "\n",
      "36,0,[+0.04 +0.03]\n",
      "37,0,[+0.04 +0.03]\n",
      "38,0,[+0.08 +0.04]\n",
      "39,0,[+0.04 +0.03]\n",
      "\n",
      "40,0,[+0.04 +0.03]\n",
      "41,0,[+0.04 +0.03]\n",
      "42,0,[+0.04 +0.03]\n",
      "43,0,[+0.07 +0.02]\n",
      "\n",
      "44,0,[+0.04 +0.03]\n",
      "45,0,[+0.04 +0.03]\n",
      "46,0,[+0.04 +0.03]\n",
      "47,0,[+0.04 +0.03]\n",
      "\n",
      "48,0,[+0.04 +0.03]\n",
      "49,0,[+0.04 +0.03]\n",
      "50,0,[+0.04 +0.03]\n",
      "51,0,[+0.04 +0.03]\n",
      "\n",
      "52,0,[+0.06 +0.01]\n",
      "53,0,[+0.04 +0.03]\n",
      "54,0,[+0.04 +0.03]\n",
      "55,0,[+0.04 +0.03]\n",
      "\n",
      "56,0,[+0.04 +0.03]\n",
      "57,0,[+0.04 +0.03]\n",
      "58,0,[+0.04 +0.03]\n",
      "59,0,[+0.04 +0.03]\n",
      "\n",
      "60,0,[+0.04 +0.03]\n",
      "61,0,[+0.04 +0.03]\n",
      "62,0,[+0.04 +0.03]\n",
      "63,0,[+0.04 +0.03]\n",
      "\n",
      "64,0,[+0.04 +0.03]\n",
      "65,0,[+0.05 +0.03]\n",
      "66,0,[+0.04 +0.03]\n",
      "67,0,[+0.04 +0.03]\n",
      "\n",
      "68,0,[+0.04 +0.03]\n",
      "69,0,[+0.04 +0.03]\n",
      "70,0,[+0.04 +0.03]\n",
      "71,0,[+0.04 +0.03]\n",
      "\n",
      "72,0,[+0.04 +0.03]\n",
      "73,0,[+0.04 +0.03]\n",
      "74,0,[+0.04 +0.03]\n",
      "75,0,[+0.04 +0.03]\n",
      "\n",
      "76,0,[+0.04 +0.03]\n",
      "77,0,[+0.04 +0.03]\n",
      "78,0,[+0.04 +0.03]\n",
      "79,0,[+0.06 +0.02]\n",
      "\n",
      "80,0,[+0.04 +0.03]\n",
      "81,0,[+0.04 +0.03]\n",
      "82,0,[+0.04 +0.03]\n",
      "83,0,[+0.04 +0.03]\n",
      "\n",
      "84,0,[+0.04 +0.03]\n",
      "85,0,[+0.05 +0.02]\n",
      "86,0,[+0.04 +0.03]\n",
      "87,0,[+0.04 +0.03]\n",
      "\n",
      "88,0,[+0.04 +0.03]\n",
      "89,0,[+0.04 +0.03]\n",
      "90,0,[+0.04 +0.03]\n",
      "91,0,[+0.04 +0.03]\n",
      "\n",
      "92,0,[+0.04 +0.03]\n",
      "93,0,[+0.04 +0.03]\n",
      "94,0,[+0.04 +0.03]\n",
      "95,0,[+0.04 +0.03]\n",
      "\n",
      "96,0,[+0.04 +0.03]\n",
      "97,0,[+0.04 +0.03]\n",
      "98,0,[+0.04 +0.03]\n",
      "99,0,[+0.04 +0.03]\n",
      "\n",
      "100,0,[+0.04 +0.03]\n",
      "101,0,[+0.04 +0.03]\n",
      "102,0,[+0.04 +0.03]\n",
      "103,0,[+0.04 +0.03]\n",
      "\n",
      "104,0,[+0.04 +0.03]\n",
      "105,0,[+0.04 +0.03]\n",
      "106,0,[+0.04 +0.03]\n",
      "107,0,[+0.04 +0.03]\n",
      "\n",
      "108,0,[+0.04 +0.03]\n",
      "109,0,[+0.04 +0.03]\n",
      "110,0,[+0.04 +0.03]\n",
      "111,0,[+0.07 +0.02]\n",
      "\n",
      "112,0,[+0.06 +0.02]\n",
      "113,0,[+0.04 +0.03]\n",
      "114,0,[+0.04 +0.03]\n",
      "115,0,[+0.04 +0.03]\n",
      "\n",
      "116,0,[+0.04 +0.03]\n",
      "117,0,[+0.04 +0.03]\n",
      "118,0,[+0.04 +0.03]\n",
      "119,0,[+0.04 +0.03]\n",
      "\n",
      "120,0,[+0.07 +0.03]\n",
      "121,0,[+0.04 +0.03]\n",
      "122,0,[+0.04 +0.03]\n",
      "123,0,[+0.06 +0.02]\n",
      "\n",
      "124,0,[+0.04 +0.03]\n",
      "125,0,[+0.04 +0.03]\n",
      "126,0,[+0.04 +0.03]\n",
      "127,0,[+0.04 +0.03]\n",
      "\n",
      "128,0,[+0.09 +0.03]\n",
      "129,0,[+0.04 +0.03]\n",
      "130,0,[+0.06 +0.02]\n",
      "131,0,[+0.07 +0.02]\n",
      "\n",
      "132,0,[+0.04 +0.03]\n",
      "133,0,[+0.06 +0.02]\n",
      "134,0,[+0.04 +0.03]\n",
      "135,0,[+0.04 +0.03]\n",
      "\n",
      "136,0,[+0.04 +0.03]\n",
      "137,0,[+0.04 +0.03]\n",
      "138,0,[+0.04 +0.03]\n",
      "139,1,[+0.01 +0.04]\n",
      "\n",
      "140,0,[+0.04 +0.03]\n",
      "141,0,[+0.04 +0.03]\n",
      "142,0,[+0.04 +0.03]\n",
      "143,0,[+0.06 +0.02]\n",
      "\n",
      "144,0,[+0.04 +0.03]\n",
      "145,0,[+0.06 +0.02]\n",
      "146,0,[+0.04 +0.03]\n",
      "147,0,[+0.06 +0.02]\n",
      "\n",
      "148,0,[+0.04 +0.03]\n",
      "149,0,[+0.04 +0.03]\n",
      "150,0,[+0.06 +0.02]\n",
      "151,0,[+0.04 +0.03]\n",
      "\n",
      "152,0,[+0.04 +0.03]\n",
      "153,0,[+0.05 +0.03]\n",
      "154,0,[+0.04 +0.03]\n",
      "155,0,[+0.04 +0.03]\n",
      "\n",
      "156,0,[+0.04 +0.03]\n",
      "157,0,[+0.04 +0.03]\n",
      "158,0,[+0.04 +0.03]\n",
      "159,0,[+0.07 +0.03]\n",
      "\n",
      "160,0,[+0.04 +0.03]\n",
      "161,0,[+0.04 +0.03]\n",
      "162,0,[+0.04 +0.03]\n",
      "163,0,[+0.07 +0.03]\n",
      "\n",
      "164,0,[+0.04 +0.03]\n",
      "165,0,[+0.05 +0.03]\n",
      "166,0,[+0.07 +0.01]\n",
      "167,0,[+0.04 +0.03]\n",
      "\n",
      "168,0,[+0.04 +0.03]\n",
      "169,0,[+0.04 +0.03]\n",
      "170,0,[+0.04 +0.03]\n",
      "171,0,[+0.04 +0.03]\n",
      "\n",
      "172,0,[+0.06 +0.03]\n",
      "173,0,[+0.04 +0.03]\n",
      "174,0,[+0.04 +0.03]\n",
      "175,0,[+0.07 +0.01]\n",
      "\n",
      "176,0,[+0.07 +0.02]\n",
      "177,0,[+0.04 +0.03]\n",
      "178,0,[+0.04 +0.03]\n",
      "179,0,[+0.04 +0.03]\n",
      "\n",
      "180,0,[+0.04 +0.03]\n",
      "181,0,[+0.04 +0.03]\n",
      "182,0,[+0.04 +0.03]\n",
      "183,0,[+0.04 +0.03]\n",
      "\n",
      "184,0,[+0.04 +0.03]\n",
      "185,0,[+0.04 +0.03]\n",
      "186,0,[+0.04 +0.03]\n",
      "187,0,[+0.04 +0.03]\n",
      "\n",
      "188,0,[+0.04 +0.03]\n",
      "189,0,[+0.04 +0.03]\n",
      "190,0,[+0.04 +0.03]\n",
      "191,0,[+0.04 +0.03]\n",
      "\n",
      "192,0,[+0.04 +0.03]\n",
      "193,0,[+0.04 +0.03]\n",
      "194,0,[+0.04 +0.03]\n",
      "195,0,[+0.04 +0.03]\n",
      "\n",
      "196,0,[+0.04 +0.03]\n",
      "197,0,[+0.04 +0.03]\n",
      "198,0,[+0.04 +0.03]\n",
      "199,0,[+0.04 +0.03]\n",
      "\n",
      "200,0,[+0.04 +0.03]\n",
      "201,0,[+0.04 +0.03]\n",
      "202,0,[+0.04 +0.03]\n",
      "203,0,[+0.04 +0.03]\n",
      "\n",
      "204,0,[+0.04 +0.03]\n",
      "205,0,[+0.04 +0.03]\n",
      "206,0,[+0.04 +0.03]\n",
      "207,0,[+0.04 +0.03]\n",
      "\n",
      "208,0,[+0.04 +0.03]\n",
      "209,0,[+0.04 +0.03]\n",
      "210,0,[+0.04 +0.03]\n",
      "211,0,[+0.04 +0.03]\n",
      "\n",
      "212,0,[+0.04 +0.03]\n",
      "213,0,[+0.04 +0.03]\n",
      "214,0,[+0.04 +0.03]\n",
      "215,0,[+0.04 +0.03]\n",
      "\n",
      "216,0,[+0.04 +0.03]\n",
      "217,0,[+0.04 +0.03]\n",
      "218,0,[+0.04 +0.03]\n",
      "219,0,[+0.04 +0.03]\n",
      "\n",
      "220,0,[+0.04 +0.03]\n",
      "221,0,[+0.04 +0.03]\n",
      "222,0,[+0.04 +0.03]\n",
      "223,0,[+0.04 +0.03]\n",
      "\n",
      "224,0,[+0.04 +0.03]\n",
      "225,0,[+0.04 +0.03]\n",
      "226,0,[+0.04 +0.03]\n",
      "227,0,[+0.04 +0.03]\n",
      "\n",
      "228,0,[+0.04 +0.03]\n",
      "229,0,[+0.04 +0.03]\n",
      "230,0,[+0.04 +0.03]\n",
      "231,0,[+0.04 +0.03]\n",
      "\n",
      "232,0,[+0.04 +0.03]\n",
      "233,0,[+0.04 +0.03]\n",
      "234,0,[+0.04 +0.03]\n",
      "235,0,[+0.04 +0.03]\n",
      "\n",
      "236,0,[+0.04 +0.03]\n",
      "237,0,[+0.04 +0.03]\n",
      "238,0,[+0.04 +0.03]\n",
      "239,0,[+0.04 +0.03]\n",
      "\n",
      "240,0,[+0.04 +0.03]\n",
      "241,0,[+0.04 +0.03]\n",
      "242,0,[+0.04 +0.03]\n",
      "243,0,[+0.04 +0.03]\n",
      "\n",
      "244,0,[+0.04 +0.03]\n",
      "245,0,[+0.04 +0.03]\n",
      "246,0,[+0.04 +0.03]\n",
      "247,0,[+0.04 +0.03]\n",
      "\n",
      "248,0,[+0.04 +0.03]\n",
      "249,0,[+0.04 +0.03]\n",
      "250,0,[+0.04 +0.03]\n",
      "251,0,[+0.04 +0.03]\n",
      "\n",
      "252,0,[+0.04 +0.03]\n",
      "253,0,[+0.04 +0.03]\n",
      "254,0,[+0.04 +0.03]\n",
      "255,0,[+0.04 +0.03]\n",
      "\n",
      "256,0,[+0.04 +0.03]\n",
      "257,0,[+0.04 +0.03]\n",
      "258,0,[+0.04 +0.03]\n",
      "259,0,[+0.04 +0.03]\n",
      "\n",
      "260,0,[+0.04 +0.03]\n",
      "261,0,[+0.04 +0.03]\n",
      "262,0,[+0.04 +0.03]\n",
      "263,0,[+0.04 +0.03]\n",
      "\n",
      "264,0,[+0.04 +0.03]\n",
      "265,0,[+0.04 +0.03]\n",
      "266,0,[+0.04 +0.03]\n",
      "267,0,[+0.04 +0.03]\n",
      "\n",
      "268,0,[+0.04 +0.03]\n",
      "269,0,[+0.04 +0.03]\n",
      "270,0,[+0.04 +0.03]\n",
      "271,0,[+0.04 +0.03]\n",
      "\n",
      "272,0,[+0.04 +0.03]\n",
      "273,0,[+0.04 +0.03]\n",
      "274,0,[+0.04 +0.03]\n",
      "275,0,[+0.04 +0.03]\n",
      "\n",
      "276,0,[+0.04 +0.03]\n",
      "277,0,[+0.04 +0.03]\n",
      "278,0,[+0.04 +0.03]\n",
      "279,0,[+0.04 +0.03]\n",
      "\n",
      "280,0,[+0.04 +0.03]\n",
      "281,0,[+0.04 +0.03]\n",
      "282,0,[+0.04 +0.03]\n",
      "283,0,[+0.04 +0.03]\n",
      "\n",
      "284,0,[+0.04 +0.03]\n",
      "285,0,[+0.04 +0.03]\n",
      "286,0,[+0.04 +0.03]\n",
      "287,0,[+0.04 +0.03]\n",
      "\n",
      "288,0,[+0.04 +0.03]\n",
      "289,0,[+0.04 +0.03]\n",
      "290,0,[+0.04 +0.03]\n",
      "291,0,[+0.04 +0.03]\n",
      "\n",
      "292,0,[+0.04 +0.03]\n",
      "293,0,[+0.04 +0.03]\n",
      "294,0,[+0.04 +0.03]\n",
      "295,0,[+0.04 +0.03]\n",
      "\n",
      "296,0,[+0.04 +0.03]\n",
      "297,0,[+0.04 +0.03]\n",
      "298,0,[+0.04 +0.03]\n",
      "299,0,[+0.04 +0.03]\n",
      "\n",
      "300,0,[+0.04 +0.03]\n",
      "301,0,[+0.04 +0.03]\n",
      "302,0,[+0.04 +0.03]\n",
      "303,0,[+0.04 +0.03]\n",
      "\n",
      "304,0,[+0.04 +0.03]\n",
      "305,0,[+0.04 +0.03]\n",
      "306,0,[+0.04 +0.03]\n",
      "307,0,[+0.04 +0.03]\n",
      "\n",
      "308,0,[+0.04 +0.03]\n",
      "309,0,[+0.04 +0.03]\n",
      "310,0,[+0.04 +0.03]\n",
      "311,0,[+0.04 +0.03]\n",
      "\n",
      "312,0,[+0.04 +0.03]\n",
      "313,0,[+0.04 +0.03]\n",
      "314,0,[+0.04 +0.03]\n",
      "315,0,[+0.04 +0.03]\n",
      "\n",
      "316,0,[+0.04 +0.03]\n",
      "317,0,[+0.04 +0.03]\n",
      "318,0,[+0.04 +0.03]\n",
      "319,0,[+0.04 +0.03]\n",
      "\n",
      "320,0,[+0.04 +0.03]\n",
      "321,0,[+0.04 +0.03]\n",
      "322,0,[+0.04 +0.03]\n",
      "323,0,[+0.04 +0.03]\n",
      "\n",
      "324,0,[+0.04 +0.03]\n",
      "325,0,[+0.04 +0.03]\n",
      "326,0,[+0.04 +0.03]\n",
      "327,0,[+0.04 +0.03]\n",
      "\n",
      "328,0,[+0.04 +0.03]\n",
      "329,0,[+0.04 +0.03]\n",
      "330,0,[+0.04 +0.03]\n",
      "331,0,[+0.04 +0.03]\n",
      "\n",
      "332,0,[+0.04 +0.03]\n",
      "333,0,[+0.04 +0.03]\n",
      "334,0,[+0.04 +0.03]\n",
      "335,0,[+0.04 +0.03]\n",
      "\n",
      "336,0,[+0.04 +0.03]\n",
      "337,0,[+0.04 +0.03]\n",
      "338,0,[+0.04 +0.03]\n",
      "339,0,[+0.04 +0.03]\n",
      "\n",
      "340,0,[+0.04 +0.03]\n",
      "341,0,[+0.04 +0.03]\n",
      "342,0,[+0.04 +0.03]\n",
      "343,0,[+0.04 +0.03]\n",
      "\n",
      "344,0,[+0.04 +0.03]\n",
      "345,0,[+0.04 +0.03]\n",
      "346,0,[+0.04 +0.03]\n",
      "347,0,[+0.04 +0.03]\n",
      "\n",
      "348,0,[+0.04 +0.03]\n",
      "349,0,[+0.04 +0.03]\n",
      "350,0,[+0.04 +0.03]\n",
      "351,0,[+0.04 +0.03]\n",
      "\n",
      "352,0,[+0.04 +0.03]\n",
      "353,0,[+0.04 +0.03]\n",
      "354,0,[+0.04 +0.03]\n",
      "355,0,[+0.04 +0.03]\n",
      "\n",
      "356,0,[+0.04 +0.03]\n",
      "357,0,[+0.04 +0.03]\n",
      "358,0,[+0.04 +0.03]\n",
      "359,0,[+0.04 +0.03]\n",
      "\n",
      "360,0,[+0.04 +0.03]\n",
      "361,0,[+0.04 +0.03]\n",
      "362,0,[+0.04 +0.03]\n",
      "363,0,[+0.04 +0.03]\n",
      "\n",
      "364,0,[+0.04 +0.03]\n",
      "365,0,[+0.04 +0.03]\n",
      "366,0,[+0.04 +0.03]\n",
      "367,0,[+0.04 +0.03]\n",
      "\n",
      "368,0,[+0.04 +0.03]\n",
      "369,0,[+0.04 +0.03]\n",
      "370,0,[+0.04 +0.03]\n",
      "371,0,[+0.04 +0.03]\n",
      "\n",
      "372,0,[+0.04 +0.03]\n",
      "373,0,[+0.04 +0.03]\n",
      "374,0,[+0.04 +0.03]\n",
      "375,0,[+0.04 +0.03]\n",
      "\n",
      "376,0,[+0.04 +0.03]\n",
      "377,0,[+0.04 +0.03]\n",
      "378,0,[+0.04 +0.03]\n",
      "379,0,[+0.04 +0.03]\n",
      "\n",
      "380,0,[+0.04 +0.03]\n",
      "381,0,[+0.04 +0.03]\n",
      "382,0,[+0.04 +0.03]\n",
      "383,0,[+0.04 +0.03]\n",
      "\n",
      "================================================================\n",
      "\n",
      "Difference With NN\n",
      "[[0.03617748 0.03202141]\n",
      " [0.056135   0.01277607]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06513612 0.02628984]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.0713997  0.00476695]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05947775 0.02288673]\n",
      " [0.03617748 0.03202141]\n",
      " [0.0529948  0.02542831]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.08701479 0.01367214]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05571279 0.02436275]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06088869 0.02233358]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.08052987 0.03513808]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06961264 0.01891343]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06355955 0.01083355]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05252784 0.02561139]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03777417 0.02754556]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05665123 0.02399484]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05246249 0.0194203 ]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.04337323 0.02645344]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.07256088 0.01775759]\n",
      " [0.05968852 0.0228041 ]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.07104424 0.02955299]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06306056 0.02148212]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.08511043 0.02855717]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06257028 0.02167433]\n",
      " [0.0729601  0.01760108]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05753601 0.02364797]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.00576323 0.03685407]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05651225 0.01628665]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05756288 0.02363744]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06209666 0.02186001]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06104465 0.02227244]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05289818 0.0254662 ]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06591403 0.03411102]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06728239 0.02981932]\n",
      " [0.03617748 0.03202141]\n",
      " [0.04519585 0.02504313]\n",
      " [0.06514837 0.00960415]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.05986634 0.03034434]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.06569374 0.00918216]\n",
      " [0.07325883 0.01748397]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]\n",
      " [0.03617748 0.03202141]]\n",
      "difference [[0.02011150175306948, 0.0072336140966525325], [0.013183597058415278, 0.008662415144308981], [0.0232676459121009, 0.004588390506100028], [0.019415502471432707, 0.008657483653092587], [-0.01554840937826523, -0.004566602936160319], [-0.023039412405943722, -0.014676206788174436], [0.012937494398470216, 0.005166131487383888], [-0.0022031675954115454, -0.011852257534029364], [-0.02497911249305687, 0.008942583352566556], [-0.017349625172823423, 0.0005466664523395559], [-0.0021345952222958722, -0.011745787190643182], [-0.003242235934059534, 0.027273048891744554], [0.008538867551264463, -0.004950189374052186], [-0.0015869170280037592, -0.00012004855041836127], [0.0031894362635614404, 0.001732918244399674], [-0.0032985092472848573, 0.008641543374636546], [0.010144075089460941, 0.0008658277998492524], [-0.016787454515852923, -0.0178224609943025], [-0.0056996080302997715, -0.0074773883444387915], [-0.017855175717373897, 0.023382774000883913], [0.024120626238959157, -0.002300930838807714], [0.012571290363447417, -0.003435505267616934], [8.596250605254208e-05, -0.0017447218069288617], [0.011798422427496937, -0.01148428230008195], [0.003930324374343486, -0.005068629947981591], [-0.016608514428456494, -0.0008809150618063928], [0.006274299584636531, -0.0018791490881876274], [-0.004186348638842187, 0.003871228311480096], [0.013356909198344556, -0.0060142150868589955], [0.02017461148643307, -0.01241968690008315], [-0.01939501392441736, -0.004900081167966853], [0.018403144830521447, 0.005921934208818792], [0.012651695434321798, 0.000455183048042207], [0.027041117397502562, -0.00028542485965250136], [-0.009380330406365586, -0.002444380847181911], [-0.013070008022486142, -0.011562802735152544], [0.012967530764570474, -0.006233177117846898], [0.023808121828012174, 0.0033532244776405817], [-0.010962717236068523, -0.009144693625935934], [0.003394679411830026, -0.014510712612624575], [-0.007326534251767117, 0.013061528574479425], [-0.016570527382492695, 0.010296145711149118], [-0.01934737465294932, -0.012038861028832174], [0.0014493869423639894, 0.009663445048507198], [0.018253663504439528, -0.003228774540524358], [-0.020025633961777724, -0.004780940479658633], [0.0038597461058238747, 0.0076432090134783345], [0.0010320579173506567, -0.008038604225876139], [0.01071235445291429, 0.006254892468401711], [-0.017983396540369487, -0.015434358215983303], [0.030392642878420834, 0.006752410475299425], [-0.01211146592430071, 0.009949468861152833], [0.0033617512958805107, 0.02684653493526376], [-0.022680860104513548, -0.014544061942826793], [0.023983336030245384, -0.012243242566678463], [-0.021458410364368297, -0.008995796093726905], [0.0031736677235334604, 0.00992648613901135], [-0.0036278821084972032, -0.01104856658288202], [0.01506720282239931, -0.008321387977150298], [-0.015039461475957916, -0.0015776900837346647], [-0.021734160858420615, 0.0011261962014880028], [-0.005706942503022085, 0.00021802404592129176], [-0.018298984467601323, -0.01535683810331906], [0.007218531409153489, -0.006869804383495274], [0.02029021332935614, -0.0016529991396816504], [-0.0012025858693522073, 0.0014342689023409683], [-0.002317985476617386, 0.003055833781959637], [0.008611272277492726, -0.007450744177937157], [-0.020534465177978262, -0.007228099039744272], [-0.004024301396606686, 0.0025915598579976593], [-0.009382010211809035, -0.005865234562170044], [-0.0008038743560908196, 0.002948513951703688], [-0.01910186540868171, -0.0082658593349452], [0.021893603519708815, 0.011789754060533522], [0.018296131526542588, -0.006933160472999446], [0.034795790472456095, 0.006424590705131329], [-0.005781332378213513, -0.0015957425336723986], [0.007084227885525637, 0.019623882856693288], [-0.023795965878562635, 0.0027962593891172963], [0.00977430615157164, 0.0019808368136338787], [0.0031452409867490233, 0.0016197947910714453], [-0.03378898141030657, 0.013209721777701647], [0.00761716169695717, 0.0014114792340673768], [0.028325909362028195, -0.021292043172912205], [0.016749496740087584, 0.004268872070616915], [0.012856248613089039, 0.009347464836220381], [0.02277717281242709, 0.0008852180236420051], [-0.01764039033728151, -0.005837392420309687], [0.025725359113839247, 0.003303039324835347], [0.012645123907944991, 0.005907331378274025], [-0.010990676567424296, -0.014285864082715174], [0.010321184549583425, -0.008785745499888396], [-0.023933068814371572, -0.005630816122524567], [0.007870513568308896, -0.005487346837378258], [-0.028113617348688367, -0.0097712624074087], [-0.008523519330311431, 0.010522141243144108], [0.013569524382799042, -0.009897290255696498], [0.0028605106941159836, -0.002095355414676984], [-0.013742315006648267, 0.0009223592061320604], [0.01424968993563655, 0.019660228598347304], [-0.0210880037615691, 0.013553435995713549], [0.002599117235842087, -0.010767592516755197], [0.005369217520010086, 0.00140889772400625], [-0.02838008014782819, 0.0038790374967861974], [0.005732941696757463, -0.003506558290049866], [0.0052041849703856335, 0.00642368442890387], [0.006567399163136499, -0.013470389464382147], [-0.03312162069395405, -0.014923142867169736], [-0.024056500767027904, -0.0059245487493347765], [0.006399681652701487, 0.014507152406832965], [-0.006151425324247402, -0.012281258518008212], [-0.0031884112944007698, 0.013806685762304441], [0.013263102212466515, 0.00684039905731567], [-0.008816788883035127, 0.0033264934160561685], [0.01702832245606798, -0.009420462560761546], [-0.01723499263928211, -0.009630277653337804], [0.010758297752921225, 0.013914084256304034], [0.019974517800345273, -0.010133621451553661], [0.014634637693520837, -0.0011943568489643196], [0.016865863261123923, -0.009474779198728314], [-0.010137228345086666, 0.016269786281317228], [-0.0009561626263292072, -0.004909603532046676], [-0.010734407954453396, -0.007702132887123778], [0.009377784889984891, 0.00929919422501587], [0.010222985821597065, -0.007717010658742845], [0.009118893612258393, 0.0020749345300794184], [0.004839617354470159, 0.011053829878254637], [0.0037343082869465208, 0.009843072241188904], [-0.010567337360384371, 0.007499490690102188], [0.005992914336448524, -0.004454986687781864], [0.008798244302475916, 0.008460172243324456], [-0.009126317384749921, 0.01402785178010825], [0.004754205916644022, 0.0007595102128407985], [0.016426250614523533, -0.0002164015100791783], [0.0030866292254169495, 0.008579481737953684], [-0.022626955419238225, 0.003332460541490098], [-0.024803715095115586, 0.004523403329466692], [0.012594026542233488, -7.064856804069736e-05], [-0.009900719561274616, 0.002282921908391841], [-0.0008370321316347809, 4.557374197501629e-06], [0.023264008307320533, 0.0098512987472998], [0.002370300994304582, -0.0051297948023915005], [-0.021882134263626618, 0.008339768996142922], [0.0016571956516804598, 0.010557007773505666], [-0.0032092415575212946, 0.013190541524635627], [0.0039277626546924335, 0.011375156480600945], [-0.008236215917526553, -0.003438202584829471], [0.0007137581042176294, -0.00991494975036294], [-0.033975155088144346, -0.000788715926923679], [0.019593475932937893, 0.00035743806341208273], [0.01075927222170478, 0.003015357555749998], [-0.01936063934648123, -0.00690433467260294], [0.006586222991196863, -0.019026889632890148], [0.00771507025354113, -0.0038553735388528465], [-0.014825437068115805, 0.00974697470923807], [0.01906160176821626, -0.008972114152677783], [-0.022970421611169925, 0.001881435600158743], [-0.0016311228822186996, -0.013931301452386493], [0.010878250710971482, 0.010638677563101093], [0.00438131650320403, -0.0114022789008939], [-0.021579856333884425, 1.778009740953379e-05], [-0.016924400533848267, -0.011364663285755128], [-0.008524800736616784, 0.002238803599433757], [-0.009680009713622394, 0.005430342624837485], [-0.011929578851960786, -0.01797860820576633], [0.017513817589089334, -0.004855371782651722], [-0.0026151617236329916, 0.005242717552441708], [-0.012656323858975423, -0.0010196373189342647], [0.02469332992568818, -0.0030609356872895073], [0.004686719336281446, 0.0058721665215386645], [-0.018293798210549272, -0.000837689260747676], [-0.0028869080354068863, 0.010680189658092268], [0.0019606361882449283, -0.00624998581642975], [-0.0007184288513301662, -0.0033190679520335546], [-0.020087245754602304, -0.00922385485584826], [-0.003137124139069608, 0.011484296016144948], [-0.0014630590247676628, 0.00911818440287971], [-0.012353289094518216, -0.006971149572098798], [-0.026583189553774703, 0.011733276132801632], [-0.01826232968946678, -0.005229719021701329], [0.004894343513978945, -0.022345119685126216], [-0.010865581519063826, -0.015328591957804432], [0.000572472924888906, -0.01058856972583103], [-0.01983409531969533, 0.0002567799871096149], [-0.0028793823252380585, 0.0032896379414353097], [0.017823660587479383, -0.001314406912537494], [0.009001496104560802, -0.00013852787153476043], [-0.018723207059379784, -0.011202642595225524], [-0.024668705275486813, -0.00700947841004107], [-0.026563488518078625, -0.003314487066798818], [-0.021122755556130364, -0.005797889945555586], [0.008896866294595837, 0.007628608522480679], [0.009177289986607981, 0.0012000434810006053], [0.004208164518527097, -0.0020015731547477315], [-0.0019456081627450203, -0.004378089729290012], [-0.003178979356258299, -0.0023495262870420405], [0.0021130023084704047, -0.0010593133729659455], [0.005043651327440349, -0.005309194781343698], [0.0038567171845815956, -0.002691739412463215], [0.004602050777717866, 7.797142869471474e-05], [0.004596849946379052, -0.005395711088656094], [0.002985477273930802, -0.0015401934398420573], [0.0028972797870302144, -0.0012244602878369107], [0.004588870377886592, -0.0009733968581176512], [-0.003863476685693215, 0.002043356023129425], [0.004040008824957128, 0.0017260067239265459], [0.0019926878942548715, -0.0023086761717653476], [0.00597479976756031, -0.0037875986612811788], [0.007266090268378239, -0.002015174032228409], [0.003068883038655136, 0.0019661791683850335], [0.004448661592558301, -0.000754399348152017], [0.002924579029641765, -0.0011822374511020611], [0.005729197947435601, -0.0012508461043715322], [-0.0030683453232577956, -0.002153401772541877], [0.008439642531668401, 0.002175878875325228], [0.011004924789533757, -0.002253224839348516], [0.0011491782444812207, -0.00022350726365551188], [0.007441986591894448, 0.00044274504836773476], [0.005550844833677411, -0.004646668145578216], [0.003908417023316006, -0.001750227012487629], [0.010088032267638762, -0.0007084743987259903], [-0.0011952986522902609, -0.002266734079909509], [0.002489043581446193, -0.0007095063459494205], [0.0019478526290263726, -7.369711015814406e-05], [0.0021423419509289388, -0.0030554389619853774], [0.007689566919803555, -0.0009052652864793287], [-0.00012767042406994916, -0.0026252028720482254], [0.004371091129352196, -0.0007521130973518683], [0.002358077706187185, -0.004375548771524941], [0.008186017506939432, -0.002344987848066391], [-0.0006666985050283389, 0.000771732359511286], [-0.0012115607285820493, -0.00014449135647747607], [-0.0025048294296345017, 0.0006327809467152334], [-0.006041004437526351, -0.00017942892038100983], [0.002145220699942052, -0.0007233743611961274], [0.012891300567376009, -0.0018908017758370727], [0.0027968733429989817, 0.000872926083272503], [0.002952088535155495, -0.0016945637953992392], [0.006775520971364447, 0.0006465376863969627], [0.010362573147604526, -0.002024565592489109], [-0.0061144578270302535, -0.0009001180937780323], [0.008406295174096863, -0.003938444785324322], [0.010517020430308409, -0.0006322915743799465], [0.00133917168401574, -0.0035066651652082698], [0.0047286120515564675, -0.0027077200243531656], [0.00667154613559863, -0.0022533367545625217], [0.003661772269437119, -0.001007651738853605], [0.003509876086623717, -0.0026668606180985203], [0.0015963759398957278, -0.0010879421292903958], [-0.002037027986232634, -0.002358945382846079], [0.003753385887034222, -0.004812091799504977], [0.0020319334544154355, 0.0009253054661166188], [0.003808156390777147, 0.0012808162200659834], [-0.0004195901938526328, -0.0006905748716608262], [0.0025975043694923677, 0.000384499745686738], [0.004910874417601095, -0.0038184399385725876], [0.0015189175255789708, -0.0035865479802323387], [-0.0011771372260870674, -0.0009781720736469456], [-0.0017680548152303743, -0.0027377981823289398], [0.0024197170046353564, -0.004254552240987943], [0.006394387065852325, -0.0039396932369690045], [0.003218680244000967, -0.006326894342188222], [0.005043487956905873, -0.004295758817977866], [0.0005638002287960131, -0.0039801553387356185], [0.0012966189868308456, -0.005030913124739345], [0.0011500487134216211, -0.0010266094444088894], [0.006748662148750702, -0.0007170074122159129], [0.006118881941493029, -4.156809288072272e-06], [0.01411166091308396, 0.0006363781017049083], [0.00473616223532379, -0.0025124215234114677], [0.005445884628526063, -0.0035314654540619106], [0.006160602304671962, -0.003937585034997505], [0.00027806419802018506, -0.0035029942021784673], [0.0034324819864744102, -0.0027637552139665837], [-0.004316071536702534, -0.0020494634106853135], [0.004707229500095923, -0.0026692315207870153], [0.004782579349010635, -0.004405416376506408], [0.0030428304550411886, -0.003169629825384237], [0.015322581341030227, -0.001772167193029809], [0.002817013056724757, -0.004188262357032294], [0.0025110039126501546, -2.5006883509204325e-06], [0.0066239907442323664, -0.0015284278056379719], [0.008087416726464146, -0.003201748730177454], [0.009371001145549201, -0.0019180278589351549], [0.0014449271513030382, -0.00073969366465515], [0.0011881402648751746, -0.0030018516863077258], [-0.0010390153666637314, -0.006178950945115343], [0.002707151794214449, -0.00229544957093877], [0.013666175372142056, -0.0004192745368610182], [0.012677711937727758, -0.001574556205249343], [0.00030699665660189474, -0.0032770930390798383], [-0.003565767037303526, 0.0021111915286418093], [-0.0068488305264508345, -0.0007735620725677836], [0.011582759931945012, -0.0023906470990645023], [-0.0034361281615964898, -0.0030516309604411603], [0.0034832742200512426, -0.0040562803767631335], [0.003157355150614251, -0.00038059827948301594], [0.0007701884721665539, -0.0014328363686730503], [0.007896143880645995, -0.0017429550577823492], [0.004029282502907364, -0.005352398230372025], [-0.004946553060060574, -0.0035280155620740876], [0.008931572443391461, -0.002135651379625337], [0.011726318789600752, -0.0035597257252327694], [0.002934397326039208, 0.00027435129742662406], [0.003907276603993051, 0.0003370179266711029], [0.007362311163190187, -0.00471557064234179], [0.008228614470069201, -0.002610288025333484], [-0.001233124121511317, -0.0033778930641813684], [0.008156790644420951, -0.001922063496432657], [0.005990535969679751, 0.0011559011660508822], [0.004777508510780841, -0.0025927563412816365], [0.007757607149988237, -0.002366385202700664], [0.007605516807773972, -0.0019907704102470197], [0.004824782578806308, -0.0045756960633303485], [0.004399159209471551, -0.000627325755932745], [0.004319488530881002, -0.0008361978295179581], [-0.00720041598699564, -0.0033582598177519796], [0.0077211271591089495, -0.001234365877565615], [0.0035604405382674217, -0.0034461057182247103], [0.0018117412962676965, -0.002043617769795711], [0.0008926289710228727, -0.0023608862052412923], [0.009517930592367649, 0.0003790138212496491], [-0.006575425176002847, -0.005335294594537254], [0.001956518906324735, -0.002951858677389948], [0.004343944843915072, -0.0018624455125808882], [0.0026660069672589937, 0.0018629306333394768], [0.0038269597769077165, -0.0019699474335111815], [0.005595603444115964, 0.0017883323614929642], [0.004645929301434183, -0.005797487174288459], [-0.00010620355368819168, -0.0051319588161917555], [0.008770032632357531, -0.001610624398712273], [-0.003032786686522744, -0.0029590238033293595], [0.0018405479045282072, -0.0009295336040395369], [-0.0010335801624740196, -0.0028178969894434545], [0.00391597784967096, -0.003133881897114589], [-0.0008855090268067786, -0.0018618260684713818], [0.00027369907448394903, -0.003270617176373159], [0.005584699668135386, -0.00074574146987684], [0.0021692645589472884, 0.0019250888170529584], [0.0072570420585503295, -0.0036772278568113666], [0.007133718808355491, -0.004320598973395755], [0.005567085981352471, 0.00020474441149310324], [0.005357547670917152, -0.004595382483914893], [-0.0009072416600856142, -0.0013709611979703003], [0.003480007932424929, -0.002988566766914169], [0.006995134787594989, 0.0024082696407025303], [0.009516315630560004, -0.003360000052652839], [0.005159246693949661, -0.000351425341506402], [0.010166301987298579, 0.0027646517919314856], [0.011884911365329251, -0.0006257118217453186], [0.005928020741539829, -0.0052435554136325314], [0.001406567960784158, -0.0027102196194960307], [0.005373053210548984, -0.0057455061735705686], [0.009552095572871566, 0.0010332639546522526], [0.010276184760691566, -0.006756913757827544], [-0.0014046750432685148, -0.004960238429738223], [0.007169315423931566, -0.0008955196487350978], [0.006888147492818464, -0.0012246430286202842], [0.0014346677179594564, -0.0022323509379282604], [-0.0012081693473983413, -0.0013296489929609315], [0.0026635928141396648, -0.002080954816376622], [0.009568011110580234, -0.00456962275099676], [0.0021525214479534774, -0.00017685496333727513], [0.007072489752010455, -0.0036863376028920397], [0.0073322506481111605, -0.0037693647707104996], [0.0004675187829346339, -0.002028937749177149], [0.010589928564548788, -0.004981479167038578], [0.004149976815273772, -0.0027080176043436065], [0.0017034589380543405, -0.004116192068665078], [0.002364864917767849, -0.004365029685999541], [-0.00410564912036384, -0.0014981557560636571], [0.007404868353701875, -0.0009126488769190325], [0.0005694316458032742, -0.0008137966465395774], [0.0037000645264295834, -0.003848573139908752], [0.0005269359055583081, -0.002891736533507286], [0.00198343116663751, -0.00457224387351076], [0.009943033826249503, -0.002394513207577116], [-0.00016914311176065983, -0.006811409080092], [0.005568792371722059, -7.792329432966538e-05], [0.005676527040143646, -0.0010111962859676304], [0.0014448664147943477, -0.0020824257766001684], [0.011869383971917585, 0.0026825380610570257], [0.006477832611497161, 0.0023179503918079464], [0.0015361703827972695, -0.0014177973188965673]]\n",
      "Total Error: 8.968014096401278e-05\n"
     ]
    }
   ],
   "source": [
    "# Phase 1 Optimal Policy\n",
    "print(\"Phase 1 Optimal Policy\")\n",
    "print_policy(P_opt1,len(environment))\n",
    "print(\"\\nOptimal Q = \",Q_opt)\n",
    "print(\"================================================================\")\n",
    "# Phase 2 - Tabular Q-Learning Optimal Policy\n",
    "print(\"Phase 2 - Tubular Q-Learning Optimal Policy\")\n",
    "print(np.argmax(Q_tubular,axis=1))\n",
    "print(\"================================================================\")\n",
    "\n",
    "# Phase 2 - DQN Optimal Policy\n",
    "print(\"Phase 2 - DQN Optimal Policy\")\n",
    "Q_NN = dql.print_dqn(optimal_network)\n",
    "print(\"================================================================\")\n",
    "\n",
    "# Output difference\n",
    "print(\"\\nDifference With NN\")\n",
    "print(Q_NN)\n",
    "difference,total_error = calculate_difference_and_mse(Q_opt,Q_NN)\n",
    "print(f\"difference {difference}\\nTotal Error: {total_error}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
